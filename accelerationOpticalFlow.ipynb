{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfhsfcRzYUNgKzm0aotpLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nao329/accelerationOpticalFlow/blob/sub/accelerationOpticalFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kJ6tDzaZ2n3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%cd /content/drive/MyDrive/創成課題/第4回/"
      ],
      "metadata": {
        "id": "cwxILUziszE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### オプティカルフロー\n",
        "\n",
        "- 動画ファイル\n",
        "  *   uniformMotionWithNoEdit\n",
        "  *   fall_ball\n",
        "  *   single_loop_ball\n",
        "  *   bound_ball_with_damp\n",
        "  *   bound_ball_mov\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gIjzpd_G0d9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### オプティカルフロー関数の実装"
      ],
      "metadata": {
        "id": "3SLs7y4UhGT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def calcOpticalFlowFarneback(prev, next, flow=None, pyr_scale=0.5, levels=3, winsize=15,\n",
        "                             iterations=3, poly_n=5, poly_sigma=1.2, flags=0):\n",
        "    \"\"\"\n",
        "    Farneback法を使用してオプティカルフローを計算します。\n",
        "\n",
        "    引数:\n",
        "        prev (ndarray): 前のフレーム（グレースケール画像）。\n",
        "        next (ndarray): 次のフレーム（グレースケール画像）。\n",
        "        flow (ndarray, optional): 初期フロー（必要に応じて）。デフォルトはNone。\n",
        "        pyr_scale (float, optional): 各ピラミッドレベルでの画像スケール。デフォルトは0.5。\n",
        "        levels (int, optional): ピラミッドレベルの数。デフォルトは3。\n",
        "        winsize (int, optional): 窓サイズ。デフォルトは15。\n",
        "        iterations (int, optional): 各レベルでの反復回数。デフォルトは3。\n",
        "        poly_n (int, optional): 多項式展開のピクセル近傍サイズ。デフォルトは5。\n",
        "        poly_sigma (float, optional): Gaussian標準偏差。デフォルトは1.2。\n",
        "        flags (int, optional): オプションフラグ。デフォルトは0。\n",
        "\n",
        "    戻り値:\n",
        "        flow (ndarray): 計算されたオプティカルフロー。\n",
        "    \"\"\"\n",
        "    # OpenCVのcalcOpticalFlowFarneback関数を使用してフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(\n",
        "        prev, next, flow, pyr_scale, levels, winsize,\n",
        "        iterations, poly_n, poly_sigma, flags\n",
        "    )\n",
        "    return flow\n"
      ],
      "metadata": {
        "id": "I0EvHWy1hOLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calc_farneback_optical_flow(prev0, next0, flow0=None, pyr_scale=0.5, num_levels=5, flags=0,\n",
        "                                win_size=15, num_iters=3, poly_n=5, poly_sigma=1.2):\n",
        "    \"\"\"\n",
        "    Farneback法を使用して密なオプティカルフローを計算します。\n",
        "\n",
        "    引数:\n",
        "        prev0 (numpy.ndarray): 前のフレーム（グレースケール画像）。\n",
        "        next0 (numpy.ndarray): 次のフレーム（グレースケール画像）。\n",
        "        flow0 (numpy.ndarray, optional): 初期フローまたは出力フロー。デフォルトはNone。\n",
        "        pyr_scale (float): 各ピラミッドレベルでの画像スケール（1未満）。\n",
        "        num_levels (int): ピラミッドレベルの数。\n",
        "        flags (int): アルゴリズムのフラグ。\n",
        "        win_size (int): 平均化に使用されるウィンドウサイズ。\n",
        "        num_iters (int): 各ピラミッドレベルでの反復回数。\n",
        "        poly_n (int): 多項式展開の近傍サイズ。\n",
        "        poly_sigma (float): ガウス分布の標準偏差。\n",
        "\n",
        "    戻り値:\n",
        "        numpy.ndarray: 計算されたフロー（形状 (h, w, 2) のnumpy配列）。\n",
        "    \"\"\"\n",
        "\n",
        "    min_size = 32\n",
        "    img = [prev0, next0]\n",
        "\n",
        "    # 入力の検証\n",
        "    assert prev0.shape == next0.shape and len(prev0.shape) == 2, \"入力画像は同じサイズのグレースケール画像である必要があります。\"\n",
        "    assert pyr_scale < 1, \"pyr_scaleは1未満でなければなりません。\"\n",
        "\n",
        "    if flags & cv2.OPTFLOW_USE_INITIAL_FLOW:\n",
        "        assert flow0 is not None, \"OPTFLOW_USE_INITIAL_FLOWフラグが設定されている場合、初期フローを提供する必要があります。\"\n",
        "        assert flow0.shape[:2] == prev0.shape[:2] and flow0.shape[2] == 2 and flow0.dtype == np.float32, \"flow0の次元が正しくありません。\"\n",
        "    else:\n",
        "        flow0 = np.zeros((prev0.shape[0], prev0.shape[1], 2), dtype=np.float32)\n",
        "\n",
        "    prevFlow = None\n",
        "    levels = num_levels\n",
        "\n",
        "    # 画像サイズとmin_sizeに基づいてレベル数を調整\n",
        "    scale = 1.0\n",
        "    for k in range(levels):\n",
        "        scale *= pyr_scale\n",
        "        if prev0.shape[1]*scale < min_size or prev0.shape[0]*scale < min_size:\n",
        "            break\n",
        "    levels = k\n",
        "\n",
        "    for k in range(levels, -1, -1):\n",
        "        # このレベルのスケールを計算\n",
        "        scale = pyr_scale ** k\n",
        "\n",
        "        sigma = (1.0 / scale - 1) * 0.5\n",
        "        smooth_sz = int(round(sigma * 5)) | 1\n",
        "        smooth_sz = max(smooth_sz, 3)\n",
        "\n",
        "        width = int(round(prev0.shape[1] * scale))\n",
        "        height = int(round(prev0.shape[0] * scale))\n",
        "\n",
        "        if k > 0:\n",
        "            flow = np.zeros((height, width, 2), dtype=np.float32)\n",
        "        else:\n",
        "            flow = flow0\n",
        "\n",
        "        if prevFlow is None:\n",
        "            if flags & cv2.OPTFLOW_USE_INITIAL_FLOW:\n",
        "                flow = cv2.resize(flow0, (width, height), interpolation=cv2.INTER_AREA)\n",
        "                flow *= scale\n",
        "            else:\n",
        "                flow = np.zeros((height, width, 2), dtype=np.float32)\n",
        "        else:\n",
        "            flow = cv2.resize(prevFlow, (width, height), interpolation=cv2.INTER_LINEAR)\n",
        "            flow *= 1.0 / pyr_scale\n",
        "\n",
        "        # このピラミッドレベルの画像を準備\n",
        "        R = [None, None]\n",
        "        for i in range(2):\n",
        "            fimg = img[i].astype(np.float32)\n",
        "            fimg = cv2.GaussianBlur(fimg, (smooth_sz, smooth_sz), sigma)\n",
        "            I = cv2.resize(fimg, (width, height), interpolation=cv2.INTER_LINEAR)\n",
        "            # Farnebackの多項式展開を行う（内部関数のため直接使用不可）\n",
        "            R[i] = farneback_poly_exp(I, poly_n, poly_sigma)\n",
        "\n",
        "        # フローマトリックスの計算\n",
        "        M = farneback_update_matrices(R[0], R[1], flow)\n",
        "\n",
        "        # フローを反復的に更新\n",
        "        for i in range(num_iters):\n",
        "            if flags & cv2.OPTFLOW_FARNEBACK_GAUSSIAN:\n",
        "                flow = farneback_update_flow_gaussian(R[0], R[1], flow, M, win_size, i < num_iters - 1)\n",
        "            else:\n",
        "                flow = farneback_update_flow(R[0], R[1], flow, M, win_size, i < num_iters - 1)\n",
        "\n",
        "        prevFlow = flow.copy()\n",
        "\n",
        "    return flow\n",
        "\n",
        "def farneback_poly_exp(I, poly_n, poly_sigma):\n",
        "    \"\"\"\n",
        "    画像の多項式展開を計算します。\n",
        "\n",
        "    OpenCVのFarneback実装の内部関数であり、Pythonでは直接アクセスできません。\n",
        "    この関数を再実装するには高度な数学的知識が必要です。\n",
        "\n",
        "    引数:\n",
        "        I (numpy.ndarray): 現在のピラミッドレベルの入力画像。\n",
        "        poly_n (int): ピクセル近傍のサイズ。\n",
        "        poly_sigma (float): ガウシアンの標準偏差。\n",
        "\n",
        "    戻り値:\n",
        "        numpy.ndarray: 画像の多項式展開結果。\n",
        "    \"\"\"\n",
        "    # この部分は高度な実装が必要なため、ここでは擬似的に入力をそのまま返します。\n",
        "    # 実際のアプリケーションでは、この部分の正確な実装が必要です。\n",
        "    return I  # 擬似的な戻り値\n",
        "\n",
        "def farneback_update_matrices(R0, R1, flow):\n",
        "    \"\"\"\n",
        "    Farnebackアルゴリズムで使用されるフローマトリックスを計算します。\n",
        "\n",
        "    引数:\n",
        "        R0 (numpy.ndarray): 最初の画像の多項式展開。\n",
        "        R1 (numpy.ndarray): 2番目の画像の多項式展開。\n",
        "        flow (numpy.ndarray): 現在のフロー推定。\n",
        "\n",
        "    戻り値:\n",
        "        numpy.ndarray: フローマトリックス。\n",
        "    \"\"\"\n",
        "    # この部分も高度な実装が必要です。\n",
        "    M = np.zeros_like(flow)  # 擬似的な戻り値\n",
        "    return M\n",
        "\n",
        "def farneback_update_flow(R0, R1, flow, M, win_size, update_matrices):\n",
        "    \"\"\"\n",
        "    ボックスフィルターを使用してフローを更新します。\n",
        "\n",
        "    引数:\n",
        "        R0, R1, flow, M: 前述の通り。\n",
        "        win_size (int): ウィンドウサイズ。\n",
        "        update_matrices (bool): マトリックスを更新するかどうか。\n",
        "\n",
        "    戻り値:\n",
        "        numpy.ndarray: 更新されたフロー。\n",
        "    \"\"\"\n",
        "    # この部分も高度な実装が必要です。\n",
        "    return flow  # 擬似的な戻り値\n",
        "\n",
        "def farneback_update_flow_gaussian(R0, R1, flow, M, win_size, update_matrices):\n",
        "    \"\"\"\n",
        "    ガウシアンブラーを使用してフローを更新します。\n",
        "\n",
        "    引数:\n",
        "        R0, R1, flow, M: 前述の通り。\n",
        "        win_size (int): ウィンドウサイズ。\n",
        "        update_matrices (bool): マトリックスを更新するかどうか。\n",
        "\n",
        "    戻り値:\n",
        "        numpy.ndarray: 更新されたフロー。\n",
        "    \"\"\"\n",
        "    # この部分も高度な実装が必要です。\n",
        "    return flow  # 擬似的な戻り値\n"
      ],
      "metadata": {
        "id": "wOYnaqysii_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### farneback法のスクラッチ"
      ],
      "metadata": {
        "id": "5bRisFgIPtnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def calc_optical_flow_farneback_scratch(old_gray, frame_gray, num_iterations=3, window_size=15, poly_n=5, poly_sigma=1.2):\n",
        "    h, w = old_gray.shape\n",
        "    flow = np.zeros((h, w, 2), dtype=np.float64)\n",
        "\n",
        "    # ピラミッド構造を作成し、段階的に追跡を行う\n",
        "    for iteration in range(num_iterations):\n",
        "        for y in range(0, h - window_size, window_size):\n",
        "            for x in range(0, w - window_size, window_size):\n",
        "                # 窓を切り出して、それぞれの差分を取る\n",
        "                old_patch = old_gray[y:y + window_size, x:x + window_size]\n",
        "                new_patch = frame_gray[y:y + window_size, x:x + window_size]\n",
        "\n",
        "                # グラディエント計算（画像の勾配を計算して物体の動きを推定する）\n",
        "                grad_x = cv2.Sobel(old_patch, cv2.CV_64F, 1, 0, ksize=poly_n)\n",
        "                grad_y = cv2.Sobel(old_patch, cv2.CV_64F, 0, 1, ksize=poly_n)\n",
        "                grad_t = (new_patch.astype(np.float64) - old_patch.astype(np.float64))\n",
        "\n",
        "                # 最小二乗法で移動ベクトルを計算\n",
        "                A = np.stack((grad_x.ravel(), grad_y.ravel()), axis=1)\n",
        "                b = -grad_t.ravel()\n",
        "\n",
        "                # 方程式を解く（最小二乗解）\n",
        "                nu = np.linalg.lstsq(A, b, rcond=None)[0]\n",
        "                flow[y:y + window_size, x:x + window_size, 0] += nu[0]\n",
        "                flow[y:y + window_size, x:x + window_size, 1] += nu[1]\n",
        "\n",
        "    # ガウシアンフィルタで平滑化\n",
        "    flow[:, :, 0] = cv2.GaussianBlur(flow[:, :, 0], (poly_n, poly_n), poly_sigma)\n",
        "    flow[:, :, 1] = cv2.GaussianBlur(flow[:, :, 1], (poly_n, poly_n), poly_sigma)\n",
        "\n",
        "    return flow\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # フルスクラッチでFarneback法に基づくオプティカルフローを計算\n",
        "    flow = calc_optical_flow_farneback_scratch(old_gray, frame_gray, num_iterations=5, window_size=21, poly_n=7, poly_sigma=1.5)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 100, y + fy * 100]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    print('Farneback Optical Flow - High Precision (Scratch)')\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "    # 次のフレームの準備\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "9U6N8fDUPs0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('fall_ball.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def calc_optical_flow_farneback_scratch_with_pyramid(old_gray, frame_gray, levels=3, num_iterations=3, window_size=15, poly_n=5, poly_sigma=1.2):\n",
        "    h, w = old_gray.shape\n",
        "    flow = np.zeros((h, w, 2), dtype=np.float32)\n",
        "\n",
        "    # ピラミッド構造を作成\n",
        "    pyramids_old = [old_gray]\n",
        "    pyramids_new = [frame_gray]\n",
        "    for level in range(1, levels):\n",
        "        pyramids_old.append(cv2.pyrDown(pyramids_old[-1]))\n",
        "        pyramids_new.append(cv2.pyrDown(pyramids_new[-1]))\n",
        "\n",
        "    # 各ピラミッドレベルでオプティカルフローを計算\n",
        "    for level in reversed(range(levels)):\n",
        "        level_flow = np.zeros_like(flow)\n",
        "        pyramid_old = pyramids_old[level]\n",
        "        pyramid_new = pyramids_new[level]\n",
        "\n",
        "        scale = 2 ** level\n",
        "        current_window_size = window_size // scale\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for y in range(0, pyramid_old.shape[0] - current_window_size, current_window_size):\n",
        "                for x in range(0, pyramid_old.shape[1] - current_window_size, current_window_size):\n",
        "                    # 窓を切り出して差分を取る\n",
        "                    old_patch = pyramid_old[y:y + current_window_size, x:x + current_window_size]\n",
        "                    new_patch = pyramid_new[y:y + current_window_size, x:x + current_window_size]\n",
        "\n",
        "                    # 勾配計算\n",
        "                    grad_x = cv2.Sobel(old_patch, cv2.CV_32F, 1, 0, ksize=poly_n)\n",
        "                    grad_y = cv2.Sobel(old_patch, cv2.CV_32F, 0, 1, ksize=poly_n)\n",
        "                    grad_t = (new_patch.astype(np.float32) - old_patch.astype(np.float32))\n",
        "\n",
        "                    # 最小二乗法で移動ベクトルを計算\n",
        "                    A = np.stack((grad_x.ravel(), grad_y.ravel()), axis=1)\n",
        "                    b = -grad_t.ravel()\n",
        "\n",
        "                    # 方程式を解く\n",
        "                    if A.shape[0] > 2:  # 方程式の解を得るためには少なくとも2つの式が必要\n",
        "                        nu = np.linalg.lstsq(A, b, rcond=None)[0]\n",
        "                        level_flow[y:y + current_window_size, x:x + current_window_size, 0] += nu[0]\n",
        "                        level_flow[y:y + current_window_size, x:x + current_window_size, 1] += nu[1]\n",
        "\n",
        "        # 高い解像度のフローに追加\n",
        "        if level != levels - 1:\n",
        "            level_flow = cv2.resize(level_flow, (flow.shape[1], flow.shape[0]))\n",
        "        flow += level_flow\n",
        "\n",
        "    # ガウシアンフィルタで平滑化\n",
        "    flow[:, :, 0] = cv2.GaussianBlur(flow[:, :, 0], (poly_n, poly_n), poly_sigma)\n",
        "    flow[:, :, 1] = cv2.GaussianBlur(flow[:, :, 1], (poly_n, poly_n), poly_sigma)\n",
        "\n",
        "    return flow\n",
        "\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # フルスクラッチでFarneback法に基づくオプティカルフローを計算\n",
        "    flow = calc_optical_flow_farneback_scratch(old_gray, frame_gray, num_iterations=5, window_size=21, poly_n=7, poly_sigma=1.5)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 100, y + fy * 100]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    print('Farneback Optical Flow - High Precision (Scratch)')\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "    # 次のフレームの準備\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "7hyY_rqQ-nhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## オプティカルフローの標準実装"
      ],
      "metadata": {
        "id": "3491om2iWC4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *等速円運動*"
      ],
      "metadata": {
        "id": "HLANqfoNWLgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 50, 3, 5, 1.2, 256)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    true_velocity = (1.0, 1.0)  # 等速度円運動の理論的な速度ベクトル（仮定）\n",
        "    mse = evaluate_optical_flow(flow, true_velocity, step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "YeKuBpKEWOP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 円運動（フローを拡大）"
      ],
      "metadata": {
        "id": "KuXSMy1jsM3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()"
      ],
      "metadata": {
        "id": "9D1998smzNPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 100, y + fy * 100]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    true_velocity = (1.0, 1.0)  # 等速度円運動の理論的な速度ベクトル（仮定）\n",
        "    mse = evaluate_optical_flow(flow, true_velocity, step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "FTJSwUeLsMaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 座標変換のためのintに直さない場合"
      ],
      "metadata": {
        "id": "A2lILyvJv6--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 100, y + fy * 100]).T.reshape(-1, 2, 2)\n",
        "    print(lines)\n",
        "    lines = np.int64(lines)\n",
        "    print(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    true_velocity = (1.0, 1.0)  # 等速度円運動の理論的な速度ベクトル（仮定）\n",
        "    mse = evaluate_optical_flow(flow, true_velocity, step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "vX1dk6Ipv_UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 垂直落下運動"
      ],
      "metadata": {
        "id": "0m83-JrQWB0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('fall_ball.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 50, 3, 5, 1.2, 256)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 100, y + fy * 100]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    true_velocity = (1.0, 1.0)  # 等速度円運動の理論的な速度ベクトル（仮定）\n",
        "    mse = evaluate_optical_flow(flow, true_velocity, step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "_DYMze4A_J5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 重心のみ(この場合ソースコードがおかしい可能性あり。標準よりも精度が低い)重心情報飲み使えているかチェック"
      ],
      "metadata": {
        "id": "h1e1FZ8v2q9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('fall_ball.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity_x, true_velocity_y, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を角度の違いで計算\n",
        "    true_fx = true_velocity_x[y, x]\n",
        "    true_fy = true_velocity_y[y, x]\n",
        "    dot_product = fx * true_fx + fy * true_fy\n",
        "    magnitude_flow = np.sqrt(fx**2 + fy**2)\n",
        "    magnitude_true = np.sqrt(true_fx**2 + true_fy**2)\n",
        "    cos_theta = dot_product / (magnitude_flow * magnitude_true + 1e-5)  # 小さな値を足してゼロ除算を防止\n",
        "    angle_error = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # コサイン値をクリップして範囲を保つ\n",
        "    mean_angle_error = np.degrees(np.mean(angle_error))  # 角度誤差の平均を度数法で返す\n",
        "    return mean_angle_error\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 物体の重心を計算\n",
        "    ret, thresh = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    M = cv2.moments(thresh)\n",
        "    if M['m00'] != 0:\n",
        "        centroid_x = int(M['m10'] / M['m00'])\n",
        "        centroid_y = int(M['m01'] / M['m00'])\n",
        "    else:\n",
        "        centroid_x, centroid_y = 0, 0\n",
        "\n",
        "    # 重心以外の部分をマスク処理して物体を検知できなくする\n",
        "    mask_centroid = np.ones_like(frame_gray) * 255\n",
        "    cv2.circle(mask_centroid, (centroid_x, centroid_y), 20, 0, -1)  # 重心の周りを除いてマスク\n",
        "    frame_gray_masked = cv2.bitwise_and(frame_gray, frame_gray, mask=mask_centroid)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray_masked, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "KXbL-5HC2qqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ベクトルの大きさ通常"
      ],
      "metadata": {
        "id": "8IGsg37A2_Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('fall_ball.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 50, 3, 5, 1.2, 256)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    true_velocity = (1.0, 1.0)  # 等速度円運動の理論的な速度ベクトル（仮定）\n",
        "    mse = evaluate_optical_flow(flow, true_velocity, step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "UQPnT0tmz5jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 理論値と標準実装の比較"
      ],
      "metadata": {
        "id": "9baVAAr7YHm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    error_x = fx - true_fx\n",
        "    error_y = fy - true_fy\n",
        "    mse = np.mean(error_x**2 + error_y**2)\n",
        "    return mse\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 理論的な円運動の速度ベクトルを計算し描画\n",
        "    radius = 200  # 仮定された円運動の半径\n",
        "    omega = 1/200 # 角速度（ラジアン毎フレーム）\n",
        "    center_x, center_y = w // 2, h // 2  # 円運動の中心をフレームの中心と仮定\n",
        "    true_fx = -radius * omega * np.sin(omega * np.arange(len(x)))\n",
        "    true_fy = radius * omega * np.cos(omega * np.arange(len(y)))\n",
        "    for i in range(len(x)):\n",
        "        true_x, true_y = x[i], y[i]\n",
        "        img = cv2.arrowedLine(img, (true_x, true_y), (int(true_x + true_fx[i] * 10), int(true_y + true_fy[i] * 10)), (0, 255, 0), 1, tipLength=0.3)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価\n",
        "    mse = evaluate_optical_flow(flow, (true_fx.mean(), true_fy.mean()), step=8)\n",
        "    print(f\"Mean Squared Error (MSE) of Optical Flow: {mse}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "QYB-Sf-bYL75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 理論値とベクトルの向きで比較"
      ],
      "metadata": {
        "id": "B4_UjkaPcqYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を角度の違いで計算\n",
        "    true_fx, true_fy = true_velocity\n",
        "    dot_product = fx * true_fx + fy * true_fy\n",
        "    magnitude_flow = np.sqrt(fx**2 + fy**2)\n",
        "    magnitude_true = np.sqrt(true_fx**2 + true_fy**2)\n",
        "    cos_theta = dot_product / (magnitude_flow * magnitude_true + 1e-5)  # 小さな値を足してゼロ除算を防止\n",
        "    angle_error = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # コサイン値をクリップして範囲を保つ\n",
        "    mean_angle_error = np.degrees(np.mean(angle_error))  # 角度誤差の平均を度数法で返す\n",
        "    return mean_angle_error\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 理論的な円運動の速度ベクトルを計算し描画\n",
        "    radius = 200  # 仮定された円運動の半径\n",
        "    omega = 1/200  # 角速度（ラジアン毎フレーム）\n",
        "    center_x, center_y = w // 2, h // 2  # 円運動の中心をフレームの中心と仮定\n",
        "    true_fx = -radius * omega * np.sin(omega * np.arange(len(x)))\n",
        "    true_fy = radius * omega * np.cos(omega * np.arange(len(y)))\n",
        "    for i in range(len(x)):\n",
        "        true_x, true_y = x[i], y[i]\n",
        "        img = cv2.arrowedLine(img, (true_x, true_y), (int(true_x + true_fx[i] * 10), int(true_y + true_fy[i] * 10)), (0, 255, 0), 1, tipLength=0.3)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価（ベクトルの向きの誤差）\n",
        "    mean_angle_error = evaluate_optical_flow(flow, (true_fx.mean(), true_fy.mean()), step=8)\n",
        "    print(f\"Mean Angular Error (in degrees) of Optical Flow: {mean_angle_error}\")\n",
        "\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "XfaSHwm4coB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 評価指標修正版"
      ],
      "metadata": {
        "id": "GlzADGdjh4iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('input_video.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity_x, true_velocity_y, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を角度の違いで計算\n",
        "    true_fx = true_velocity_x[y, x]\n",
        "    true_fy = true_velocity_y[y, x]\n",
        "    dot_product = fx * true_fx + fy * true_fy\n",
        "    magnitude_flow = np.sqrt(fx**2 + fy**2)\n",
        "    magnitude_true = np.sqrt(true_fx**2 + true_fy**2)\n",
        "    cos_theta = dot_product / (magnitude_flow * magnitude_true + 1e-5)  # 小さな値を足してゼロ除算を防止\n",
        "    angle_error = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # コサイン値をクリップして範囲を保つ\n",
        "    mean_angle_error = np.degrees(np.mean(angle_error))  # 角度誤差の平均を度数法で返す\n",
        "    return mean_angle_error\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # OpenCVのFarneback法を使用してオプティカルフローを計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(old_gray, frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 10, y + fy * 10]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # 理論的な円運動の速度ベクトルを計算\n",
        "    radius = 200  # 仮定された円運動の半径\n",
        "    omega = 1/200  # 角速度（ラジアン毎フレーム）\n",
        "    center_x, center_y = w // 2, h // 2  # 円運動の中心をフレームの中心と仮定\n",
        "    true_velocity_x = -omega * (y - center_y)  # 理論的な速度ベクトルのX成分\n",
        "    true_velocity_y = omega * (x - center_x)   # 理論的な速度ベクトルのY成分\n",
        "\n",
        "    # 理論的な円運動の速度ベクトルを描画\n",
        "    for i in range(len(x)):\n",
        "        true_x, true_y = x[i], y[i]\n",
        "        img = cv2.arrowedLine(img, (true_x, true_y), (int(true_x + true_velocity_x[i] * 10), int(true_y + true_velocity_y[i] * 10)), (0, 255, 0), 1, tipLength=0.3)\n",
        "\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 理論値との誤差を評価（ベクトルの向きの誤差）\n",
        "    mean_angle_error = evaluate_optical_flow(flow, true_velocity_x, true_velocity_y, step=8)\n",
        "    print(f\"Mean Angular Error (in degrees) of Optical Flow: {mean_angle_error}\")\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray.copy()\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "AwMumrT3h7nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Farneback 改良版"
      ],
      "metadata": {
        "id": "d1V4gPfK1czm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# 動画のキャプチャを開始\n",
        "cap = cv2.VideoCapture('uniformMotionWithNoEdit.mp4')\n",
        "\n",
        "# ランダムな色を生成\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# 最初のフレームを読み込み、グレースケールに変換\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 描画用のマスクを作成\n",
        "mask = np.zeros_like(old_frame)\n",
        "# cv2_imshow(mask)\n",
        "\n",
        "def evaluate_optical_flow(flow, true_velocity_x, true_velocity_y, step=8):\n",
        "    # フローをサンプリングし、理論的な速度と比較して誤差を計算する\n",
        "    h, w = flow.shape[:2]\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    # 理論的な速度ベクトルとの誤差を角度の違いで計算\n",
        "    true_fx = true_velocity_x[y, x]\n",
        "    true_fy = true_velocity_y[y, x]\n",
        "    dot_product = fx * true_fx + fy * true_fy\n",
        "    magnitude_flow = np.sqrt(fx**2 + fy**2)\n",
        "    magnitude_true = np.sqrt(true_fx**2 + true_fy**2)\n",
        "    cos_theta = dot_product / (magnitude_flow * magnitude_true + 1e-5)  # 小さな値を足してゼロ除算を防止\n",
        "    angle_error = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # コサイン値をクリップして範囲を保つ\n",
        "    mean_angle_error = np.degrees(np.mean(angle_error))  # 角度誤差の平均を度数法で返す\n",
        "    return mean_angle_error\n",
        "\n",
        "def calc_optical_flow_farneback(prev, next, pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.1, flags=0):\n",
        "    # フローを格納するための初期化\n",
        "    flow = np.zeros((prev.shape[0], prev.shape[1], 2), dtype=np.float32)\n",
        "\n",
        "    # ピラミッドを作成\n",
        "    pyramid_prev = [prev]\n",
        "    pyramid_next = [next]\n",
        "    for level in range(1, levels):\n",
        "        pyramid_prev.append(cv2.pyrDown(pyramid_prev[-1]))\n",
        "        pyramid_next.append(cv2.pyrDown(pyramid_next[-1]))\n",
        "\n",
        "    # 最も小さいレベルから順に処理\n",
        "    for level in reversed(range(levels)):\n",
        "        # 現在のレベルの画像\n",
        "        prev_level = pyramid_prev[level]\n",
        "        next_level = pyramid_next[level]\n",
        "\n",
        "        # 拡大処理（最初のレベル以外）\n",
        "        if level < levels - 1:\n",
        "            flow = cv2.pyrUp(flow)\n",
        "            flow = cv2.resize(flow, (prev_level.shape[1], prev_level.shape[0]))\n",
        "\n",
        "        # 各ピクセルの動きを計算\n",
        "        h, w = prev_level.shape[:2]\n",
        "        A_sum = np.zeros((2, 2), dtype=np.float32)\n",
        "        b_sum = np.zeros(2, dtype=np.float32)\n",
        "        w_sum = 0\n",
        "        for y in range(h):\n",
        "            for x in range(w):\n",
        "                # 値がオーバーフローしないように型変換\n",
        "                prev_pixel = np.float32(prev_level[y, x])\n",
        "                next_pixel = np.float32(next_level[y, x])\n",
        "                Ix = (np.float32(next_level[y, min(x + 1, w - 1)]) - np.float32(next_level[y, max(x - 1, 0)])) / 2.0\n",
        "                Iy = (np.float32(next_level[min(y + 1, h - 1), x]) - np.float32(next_level[max(y - 1, 0), x])) / 2.0\n",
        "                It = next_pixel - prev_pixel\n",
        "                A = np.array([[Ix * Ix, Ix * Iy], [Ix * Iy, Iy * Iy]], dtype=np.float32)\n",
        "                b = np.array([-Ix * It, -Iy * It], dtype=np.float32)\n",
        "                weight = np.exp(-(x**2 + y**2) / (2 * winsize**2))  # 重み関数（ガウシアン）\n",
        "                A_sum += weight * A\n",
        "                b_sum += weight * b\n",
        "                w_sum += weight\n",
        "\n",
        "        # 最小二乗法による解を求める\n",
        "        if w_sum > 0:\n",
        "            flow_vector = np.linalg.solve(A_sum + 1e-5 * np.eye(2), b_sum)  # 小さな値を足して安定化\n",
        "            flow[:, :, 0] = flow_vector[0]\n",
        "            flow[:, :, 1] = flow_vector[1]\n",
        "\n",
        "    return flow\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 現在のフレームをグレースケールに変換\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # cv2_imshow(frame_gray)\n",
        "    # 物体の重心を計算\n",
        "    ret, thresh = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    # cv2_imshow(thresh)\n",
        "    M = cv2.moments(thresh)\n",
        "    if M['m00'] != 0:\n",
        "        centroid_x = int(M['m10'] / M['m00'])\n",
        "        centroid_y = int(M['m01'] / M['m00'])\n",
        "    else:\n",
        "        centroid_x, centroid_y = 0, 0\n",
        "\n",
        "    # 重心以外の部分をマスク処理して物体を検知できなくする\n",
        "    mask_centroid = np.ones_like(frame_gray) * 0\n",
        "    # cv2_imshow(mask_centroid)\n",
        "    cv2.circle(mask_centroid, (centroid_x, centroid_y), 2, (128, 128, 128), -1)  # 重心の周りを除いてマスク\n",
        "    frame_gray_masked = cv2.bitwise_and(frame_gray, frame_gray, mask=mask_centroid)\n",
        "    # cv2_imshow(frame_gray_masked)\n",
        "\n",
        "    # スクラッチ実装したFarneback法を使用してオプティカルフローを計算\n",
        "    flow = calc_optical_flow_farneback(old_gray, frame_gray_masked, pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.1, flags=0)\n",
        "\n",
        "    # フローのベクトルを描画\n",
        "    h, w = frame_gray.shape[:2]\n",
        "    step = 8  # より小さなステップでサンプリングして精度を向上させる\n",
        "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x + fx * 1000, y + fy * 1000]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines)\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), color[np.random.randint(0, len(color))].tolist(), 1)\n",
        "        # frame = cv2.circle(frame, (x1, y1), 1, color[np.random.randint(0, len(color))].tolist(), -1)\n",
        "        # mask = cv2.line(mask, (x1, y1), (x2, y2), (128, 128, 128), 1)\n",
        "        # cv2_imshow(mask)\n",
        "        frame = cv2.circle(frame, (x1, y1), 1, (128, 128, 128), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "    plt.imshow(img)\n",
        "    # 結果を表示\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 隣接するフレーム間のオプティカルフローを求めるために、現在のフレームを次のフレームの基準として更新\n",
        "    old_gray = frame_gray_masked.copy()\n",
        "\n",
        "    # # 'q'キーで終了（Matplotlibは待機処理がないためループ継続確認を手動に）\n",
        "    # user_input = input(\"Press 'q' to quit or any other key to continue: \")\n",
        "    # if user_input.lower() == 'q':\n",
        "    #     break\n",
        "\n",
        "# リリースとウィンドウの破棄\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "dW0YaiYz1fqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グレースケール変換のための配列タイプをfloat128にしたらエラーで怒られた?"
      ],
      "metadata": {
        "id": "kEzlW0piSnOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter, convolve\n",
        "\n",
        "# Load the images\n",
        "pathL = \"./uniformMotionWithNoEdit/0001.png\"\n",
        "pathR = \"./uniformMotionWithNoEdit/0002.png\"\n",
        "\n",
        "frameL = plt.imread(pathL)\n",
        "frameR = plt.imread(pathR)\n",
        "\n",
        "if frameL is None or frameR is None:\n",
        "    print(\"Could not open or find one of the images.\")\n",
        "else:\n",
        "    # Convert images to grayscale if needed and to float128 for higher precision\n",
        "    if frameL.ndim == 3:\n",
        "        frameL = np.dot(frameL[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "    if frameR.ndim == 3:\n",
        "        frameR = np.dot(frameR[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "    frameL = frameL.astype(np.uint16)\n",
        "    frameR = frameR.astype(np.float128)\n",
        "\n",
        "    # Define parameters for optical flow calculation\n",
        "    pyr_scale = 0.5\n",
        "    levels = 3\n",
        "    win_size = 15\n",
        "    iterations = 3\n",
        "    poly_n = 5\n",
        "    poly_sigma = 1.2\n",
        "\n",
        "    # Implement Farneback's optical flow method using NumPy\n",
        "    def calc_optical_flow_farneback(prev, next, pyr_scale, levels, win_size, iterations, poly_n, poly_sigma):\n",
        "        # Gaussian smoothing\n",
        "        prev_blur = gaussian_filter(prev, sigma=poly_sigma)\n",
        "        next_blur = gaussian_filter(next, sigma=poly_sigma)\n",
        "\n",
        "        # Compute image gradients using Sobel filters\n",
        "        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float128)\n",
        "        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float128)\n",
        "\n",
        "        Ix = convolve(prev_blur, sobel_x)\n",
        "        Iy = convolve(prev_blur, sobel_y)\n",
        "        It = next_blur - prev_blur\n",
        "\n",
        "        # Initialize flow vectors\n",
        "        u = np.zeros_like(prev, dtype=np.float128)\n",
        "        v = np.zeros_like(prev, dtype=np.float128)\n",
        "\n",
        "        # Iteratively update flow estimates\n",
        "        for _ in range(iterations):\n",
        "            u_avg = gaussian_filter(u, sigma=win_size / 6.0)\n",
        "            v_avg = gaussian_filter(v, sigma=win_size / 6.0)\n",
        "\n",
        "            # Calculate optical flow increment\n",
        "            num = (Ix * u_avg + Iy * v_avg + It)\n",
        "            denom = (Ix ** 2 + Iy ** 2 + 1e-10)\n",
        "\n",
        "            delta_u = -Ix * num / denom\n",
        "            delta_v = -Iy * num / denom\n",
        "\n",
        "            u += delta_u\n",
        "            v += delta_v\n",
        "\n",
        "        return u, v\n",
        "\n",
        "    # Calculate optical flow using NumPy implementation\n",
        "    flowx, flowy = calc_optical_flow_farneback(frameL, frameR, pyr_scale, levels, win_size, iterations, poly_n, poly_sigma)\n",
        "\n",
        "    # Colorize flow\n",
        "    def map_val(x, a, b, c, d):\n",
        "        x = max(min(x, b), a)\n",
        "        return c + (d - c) * (x - a) / (b - a)\n",
        "\n",
        "    def colorize_flow(u, v):\n",
        "        u_min, u_max = np.min(u), np.max(u)\n",
        "        v_min, v_max = np.min(v), np.max(v)\n",
        "        u_min, u_max = abs(u_min), abs(u_max)\n",
        "        v_min, v_max = abs(v_min), abs(v_max)\n",
        "        d_max = max(u_min, u_max, v_min, v_max)\n",
        "\n",
        "        h, w = u.shape\n",
        "        dst = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        for y in range(h):\n",
        "            for x in range(w):\n",
        "                dst[y, x, 0] = 0\n",
        "                dst[y, x, 1] = int(map_val(-v[y, x], -d_max, d_max, 0, 255))\n",
        "                dst[y, x, 2] = int(map_val(u[y, x], -d_max, d_max, 0, 255))\n",
        "\n",
        "        return dst\n",
        "\n",
        "    flow_image = colorize_flow(flowx, flowy)\n",
        "\n",
        "    # Display the optical flow using matplotlib\n",
        "    plt.imshow(flow_image)\n",
        "    plt.title('Optical Flow')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dJYZUeH_Egyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 既存のオプティカルフローライブラリを使用すると、物体がどのように認識されているか？の確認。"
      ],
      "metadata": {
        "id": "4oYEoAY0S9ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the images\n",
        "pathL = \"./uniformMotionWithNoEdit/0002.png\"\n",
        "pathR = \"./uniformMotionWithNoEdit/0001.png\"\n",
        "\n",
        "frameL = cv2.imread(pathL, cv2.IMREAD_GRAYSCALE)\n",
        "frameR = cv2.imread(pathR, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if frameL is None or frameR is None:\n",
        "    print(\"Could not open or find one of the images.\")\n",
        "else:\n",
        "    # Calculate optical flow using Farneback's method with standard precision (32-bit float)\n",
        "    flow = cv2.calcOpticalFlowFarneback(\n",
        "        frameL.astype(np.float64), frameR.astype(np.float64), None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
        "    )\n",
        "\n",
        "    # Split flow into horizontal and vertical components\n",
        "    flowx, flowy = flow[..., 0], flow[..., 1]\n",
        "\n",
        "    # Colorize flow\n",
        "    def map_val(x, a, b, c, d):\n",
        "        x = max(min(x, b), a)\n",
        "        return c + (d - c) * (x - a) / (b - a)\n",
        "\n",
        "    def colorize_flow(u, v):\n",
        "        u_min, u_max = np.min(u), np.max(u)\n",
        "        v_min, v_max = np.min(v), np.max(v)\n",
        "        u_min, u_max = abs(u_min), abs(u_max)\n",
        "        v_min, v_max = abs(v_min), abs(v_max)\n",
        "        d_max = max(u_min, u_max, v_min, v_max)\n",
        "\n",
        "        h, w = u.shape\n",
        "        dst = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "        for y in range(h):\n",
        "            for x in range(w):\n",
        "                dst[y, x, 0] = 0\n",
        "                dst[y, x, 1] = int(map_val(-v[y, x], -d_max, d_max, 0, 255))\n",
        "                dst[y, x, 2] = int(map_val(u[y, x], -d_max, d_max, 0, 255))\n",
        "\n",
        "        return dst\n",
        "\n",
        "    flow_image = colorize_flow(flowx, flowy)\n",
        "\n",
        "    print(flow)\n",
        "    # Display the optical flow\n",
        "    cv2_imshow(flow_image)\n",
        "    # cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "TzWcj5qu8C8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##重心算出"
      ],
      "metadata": {
        "id": "Jy24TN6GztLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### １フレームの重心のみ算出し表示する。"
      ],
      "metadata": {
        "id": "WeMPzB-0bhX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import Decimal, getcontext\n",
        "\n",
        "# Load the image using PIL\n",
        "try:\n",
        "    img = Image.open(\"uniformMotionWithNoEdit/0020.png\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Could not open or find the image\")\n",
        "    img = None\n",
        "\n",
        "if img:\n",
        "    # Convert the image to grayscale\n",
        "    gray = img.convert(\"L\")\n",
        "\n",
        "    # Convert grayscale image to numpy array\n",
        "    gray_np = np.array(gray)\n",
        "    # Apply binary thresholding\n",
        "    fg_mask = np.where(gray_np > 127, 255, 0)\n",
        "    fg_mask = fg_mask.astype(np.uint8)\n",
        "    # Find contours\n",
        "    contours = []\n",
        "    visited = np.zeros_like(fg_mask, dtype=bool)\n",
        "\n",
        "    def dfs(x, y, contour):\n",
        "        stack = [(x, y)]\n",
        "        while stack:\n",
        "            cx, cy = stack.pop()\n",
        "            if visited[cx, cy]:\n",
        "                continue\n",
        "            visited[cx, cy] = True\n",
        "            contour.append((cx, cy))\n",
        "            for nx, ny in [(cx - 1, cy), (cx + 1, cy), (cx, cy - 1), (cx, cy + 1)]:\n",
        "                if 0 <= nx < fg_mask.shape[0] and 0 <= ny < fg_mask.shape[1]:\n",
        "                    if fg_mask[nx, ny] == 255 and not visited[nx, ny]:\n",
        "                        stack.append((nx, ny))\n",
        "\n",
        "    # Extract contours\n",
        "    for i in range(fg_mask.shape[0]):\n",
        "        for j in range(fg_mask.shape[1]):\n",
        "            if fg_mask[i, j] == 255 and not visited[i, j]:\n",
        "                contour = []\n",
        "                dfs(i, j, contour)\n",
        "                contours.append(contour)\n",
        "\n",
        "    centroids = []\n",
        "    print(contours)\n",
        "\n",
        "    for contour in contours:\n",
        "        print(contour)\n",
        "        # Calculate centroid for each contour\n",
        "        if contour:\n",
        "            x_coords, y_coords = zip(*contour)\n",
        "            centroid_x = sum(x_coords) / len(contour)\n",
        "            centroid_y = sum(y_coords) / len(contour)\n",
        "            print(type(centroid_x), type(centroid_y))\n",
        "            centroids.append((centroid_x, centroid_y))\n",
        "\n",
        "    # Display centroids\n",
        "    print(\"Centroids:\", centroids)\n",
        "    # Optional visualization\n",
        "    plt.imshow(gray_np, cmap='gray')\n",
        "    for centroid in centroids:\n",
        "        plt.plot(centroid[1], centroid[0], 'ro')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hOTddnp40dRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# マスク処理"
      ],
      "metadata": {
        "id": "J-aPB8EuGslf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 等速円運動の場合"
      ],
      "metadata": {
        "id": "F-lghBY1EQTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"uniformMotionWithNoEdit.mp4\")\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(fg_mask, (cX, cY), 5, (0, 255, 0), -1)\n",
        "  print(f\"{count}フレーム目\")\n",
        "  cv2_imshow(fg_mask)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "EohnTVY7HYvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 落下運動の場合"
      ],
      "metadata": {
        "id": "Wl-lX3LOEk2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"fall_ball.mp4\")\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(fg_mask, (cX, cY), 5, (0, 255, 0), -1)\n",
        "  print(f\"{count}フレーム目\")\n",
        "  cv2_imshow(fg_mask)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "XHEklXWPH9o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 振り子運動"
      ],
      "metadata": {
        "id": "gTxzrJQWH18K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"single_loop_ball.mp4\")\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(fg_mask, (cX, cY), 5, (0, 255, 0), -1)\n",
        "  print(f\"{count}フレーム目\")\n",
        "  cv2_imshow(fg_mask)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "hNwsO0BuKs1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 床の摩擦を含む壁衝突運動"
      ],
      "metadata": {
        "id": "NsKHVqGzLA1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"bound_ball_mov.mp4\")\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(fg_mask, (cX, cY), 5, (0, 255, 0), -1)\n",
        "  print(f\"{count}フレーム目\")\n",
        "  cv2_imshow(fg_mask)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "9-88PTS4LChf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ばね運動"
      ],
      "metadata": {
        "id": "tLC5lT_3Lly3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"bound_ball_with_damp.mp4\")\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(fg_mask, (cX, cY), 5, (0, 255, 0), -1)\n",
        "  print(f\"{count}フレーム目\")\n",
        "  cv2_imshow(fg_mask)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "AWnZiaqXLn0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Franeback 従来"
      ],
      "metadata": {
        "id": "aQK1uGklrl5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 既存のオプティカルフローの手法"
      ],
      "metadata": {
        "id": "HcDkgtURTMnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"fall_ball.mp4\")\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "\n",
        "writer = cv2.VideoWriter(\"oldOutput_fall_ball_ver1.mp4\", fourcc, fps, (width,height))\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "t1_frame = None\n",
        "t2_frame = None\n",
        "\n",
        "def sum_flow_elements(flow, y, h, x, w):\n",
        "    region = flow[y:y+h, x:x+w]\n",
        "    total = np.sum(region, axis=(0, 1))\n",
        "    return total\n",
        "count = 0\n",
        "while True:\n",
        "  count += 1\n",
        "  is_read, frame = cap.read()\n",
        "  if not is_read:\n",
        "    break\n",
        "  # fg_mask = bg_subtractor.apply(frame)\n",
        "  # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "  # print(f\"{count}フレーム目\")\n",
        "  # cv2_imshow(fg_mask)\n",
        "  # print(fg_mask.type)\n",
        "  contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  centroids = []\n",
        "  for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            # cv2.circle(frame, (cX, cY), 5, (255, 255, 255), -1)\n",
        "  if (t1_frame is not None) and ( t2_frame is not None):\n",
        "    frame_opt = t2_frame.copy()\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    t1_frame_gray = cv2.cvtColor(t1_frame, cv2.COLOR_BGR2GRAY)\n",
        "    t2_frame_gray = cv2.cvtColor(t2_frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, fg_mask = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    _, fg_mask1 = cv2.threshold(t1_frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    _, fg_mask2 = cv2.threshold(t2_frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(fg_mask1, fg_mask2, None, 0.5, 3, 30, 3, 3, 1.1, 0)\n",
        "    nextFlow = cv2.calcOpticalFlowFarneback(fg_mask2, fg_mask, None, 0.5, 3, 30, 3, 3, 1.1, 0)\n",
        "    Flow = nextFlow - flow\n",
        "\n",
        "    totalAOF = sum_flow_elements(Flow, 0, height, 0, width)\n",
        "    for cX, cY in preCentroids:\n",
        "        point_st = (cX, cY)\n",
        "        point_ed = (cX + int(totalAOF[0]), cY + int(totalAOF[1]))\n",
        "        cv2.line(frame_opt, point_st, point_ed, (255, 0, 0), 2)\n",
        "    preCentroids = centroids.copy()\n",
        "    writer.write(frame_opt)\n",
        "    t1_frame = t2_frame.copy()\n",
        "    t2_frame = frame.copy()\n",
        "  elif t1_frame is None and t2_frame is not None:\n",
        "        t1_frame = t2_frame.copy()\n",
        "        t2_frame = frame.copy()\n",
        "        writer.write(t2_frame)\n",
        "        preCentroids = centroids.copy()\n",
        "  elif t2_frame is None:\n",
        "    t2_frame = frame.copy()\n",
        "    writer.write(t2_frame)\n",
        "\n",
        "writer.release()\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "Hr3tVaUK17cK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 重心計算方法"
      ],
      "metadata": {
        "id": "O8ROJWCdUUnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"uniformMotionWithNoEdit/0001.png\")\n",
        "if img is None:\n",
        "  print(\"Could not open or find the image\")\n",
        "# cv2_imshow(img)\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "_, fg_mask = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "centroids = []\n",
        "print(contours)\n",
        "for cnt in contours:\n",
        "    if cv2.contourArea(cnt) > 500:  # ignore small contours\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cX, cY))\n",
        "            cv2.circle(img, (cX, cY), 5, (0, 255, 0), -1)\n",
        "\n",
        "\n",
        "cv2_imshow(img)\n",
        "print(f'母数{M[\"m00\"]},横重心：{M[\"m10\"]},縦重心：{M[\"m01\"]}')"
      ],
      "metadata": {
        "id": "w83gXSwFZQur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 提案手法(提案：青木教授・実装：坂本)\n",
        "- 重心のみの速度ベクトルと角度ベクトルを求める."
      ],
      "metadata": {
        "id": "XVNm-NDgtP6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"uniformMotionWithNoEdit.mp4\")\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "\n",
        "writer = cv2.VideoWriter(\"output_uniformMotionWithNoEdit_ver3_gausian_filter.mp4\", fourcc, fps, (width, height))\n",
        "\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "def sum_flow_elements(flow, y, h, x, w):\n",
        "    region = flow[y:y+h, x:x+w]\n",
        "    total = np.sum(region, axis=(0, 1))\n",
        "    return total\n",
        "\n",
        "t1_frame = None\n",
        "t2_frame = None\n",
        "\n",
        "while True:\n",
        "    is_read, frame = cap.read()\n",
        "    if not is_read:\n",
        "        break\n",
        "\n",
        "    # fg_mask = bg_subtractor.apply(frame)\n",
        "    # _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, fg_mask = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    centroids = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 300:  # ignore small contours\n",
        "            M = cv2.moments(cnt)\n",
        "            if M[\"m00\"] != 0:\n",
        "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "                centroids.append((cX, cY))\n",
        "                cv2.circle(frame, (cX, cY), 5, (0, 0, 255), -1)\n",
        "    if t1_frame is not None and t2_frame is not None:\n",
        "        frame_opt = t2_frame.copy()\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        t1_frame_gray = cv2.cvtColor(t1_frame, cv2.COLOR_BGR2GRAY)\n",
        "        t2_frame_gray = cv2.cvtColor(t2_frame, cv2.COLOR_BGR2GRAY)\n",
        "        # cv2_imshow(frame_gray)\n",
        "        # _, fg_mask = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "        # _, fg_mask1 = cv2.threshold(t1_frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "        # _, fg_mask2 = cv2.threshold(t2_frame_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "        flow = cv2.calcOpticalFlowFarneback(t1_frame_gray, t2_frame_gray, None, 0.5, 3, 50, 3, 5, 1.2, 256)\n",
        "        nextFlow = cv2.calcOpticalFlowFarneback(t2_frame_gray, frame_gray, None, 0.5, 3, 50, 3, 5, 1.2, 256)\n",
        "        # flow = cv2.calcOpticalFlowFarneback(fg_mask1, fg_mask2, None, 0.5, 3, 30, 3, 3, 1.1, 0)\n",
        "        # nextFlow = cv2.calcOpticalFlowFarneback(fg_mask2, fg_mask, None, 0.5, 3, 30, 3, 3, 1.1, 0)\n",
        "        Flow = nextFlow - flow\n",
        "\n",
        "        for cX, cY in preCentroids:\n",
        "            point_st = (cX, cY)\n",
        "            point_ed = (cX + int(Flow[cY, cX, 0]*100), cY + int(Flow[cY, cX, 1]*100))\n",
        "            cv2.line(frame_opt, point_st, point_ed, (255, 0, 0), 2)\n",
        "        preCentroids = centroids.copy()\n",
        "        writer.write(frame_opt)\n",
        "        t1_frame = t2_frame.copy()\n",
        "        t2_frame = frame.copy()\n",
        "    elif t1_frame is None and t2_frame is not None:\n",
        "          t1_frame = t2_frame.copy()\n",
        "          t2_frame = frame.copy()\n",
        "          writer.write(t2_frame)\n",
        "          preCentroids = centroids.copy()\n",
        "    elif t2_frame is None:\n",
        "      t2_frame = frame.copy()\n",
        "      writer.write(t2_frame)\n",
        "\n",
        "cap.release()\n",
        "writer.release()\n"
      ],
      "metadata": {
        "id": "ZbP2CC4BsHel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 滑らかなオプティカルフロー"
      ],
      "metadata": {
        "id": "luigHelnwgZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def compute_optical_flow(image1, image2):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Farneback法によるオプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "    u = flow[..., 0]\n",
        "    v = flow[..., 1]\n",
        "\n",
        "    return u, v\n",
        "\n",
        "# 物体のセグメンテーションと重心計算（仮想的な例）\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = int(moments['m10'] / moments['m00'])\n",
        "        cy = int(moments['m01'] / moments['m00'])\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "# 実行例\n",
        "image1 = cv2.imread('opticalflow_val/0025.jpg')\n",
        "image2 = cv2.imread('opticalflow_val/0026.jpg')\n",
        "\n",
        "u, v = compute_optical_flow(image1, image2)\n",
        "cx, cy = segment_and_compute_centroid(image1)\n",
        "width = image1.shape[1]\n",
        "height = image1.shape[0]\n",
        "stride_H = 15\n",
        "stride_W = 15\n",
        "\n",
        "# 結果の表示\n",
        "cv2.circle(image1, (cx, cy), 5, (0, 255, 0), -1)\n",
        "point_st = (cx, cy)\n",
        "point_ed = (cx + int(u[cy, cx]), cy + int(v[cy, cx]))\n",
        "cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "\n",
        "for h in range(0, height, stride_H):\n",
        "    for w in range(0, width, stride_W):\n",
        "        point_st = (w, h)\n",
        "        point_ed = (w + int(u[h, w]*1000), h + int(v[h, w]*1000))\n",
        "        cv2.line(image1, point_st, point_ed, (0, 0, 255), 2)\n",
        "\n",
        "# 結果の画像を表示または保存\n",
        "cv2_imshow(image1)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Optical Flow (u, v):\", u, v)\n",
        "print(\"Centroid (cx, cy):\", cx, cy)\n"
      ],
      "metadata": {
        "id": "R02sbPHdwf2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# オプティカルフローの確率的削減"
      ],
      "metadata": {
        "id": "KUOwaeV60J7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def compute_optical_flow_at_keypoints(image1, image2, keypoints):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    results = []\n",
        "    for kp in keypoints:\n",
        "        cx, cy = kp.ravel()\n",
        "        cx = int(cx)\n",
        "        cy = int(cy)\n",
        "        u = flow[cy, cx, 0]\n",
        "        v = flow[cy, cx, 1]\n",
        "\n",
        "        # 大きさの計算\n",
        "        magnitude = np.sqrt(u**2 + v**2)\n",
        "\n",
        "        # 角度の計算\n",
        "        angle = np.arctan2(v, u)  # ラジアン\n",
        "        angle_degrees = np.degrees(angle)  # 度に変換\n",
        "\n",
        "        results.append((cx, cy, u, v, magnitude, angle, angle_degrees))\n",
        "\n",
        "    return results\n",
        "\n",
        "# 物体のセグメンテーションと重心計算（仮想的な例）\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = int(moments['m10'] / moments['m00'])\n",
        "        cy = int(moments['m01'] / moments['m00'])\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "# 特徴点を検出する関数\n",
        "def detect_keypoints(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    keypoints = cv2.goodFeaturesToTrack(gray, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
        "    return keypoints\n",
        "\n",
        "# 加速度ベクトルを計算する関数\n",
        "def compute_acceleration(results1, results2, dt):\n",
        "    accelerations = []\n",
        "    for (cx1, cy1, u1, v1, mag1, ang1, ang_deg1), (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) in zip(results1, results2):\n",
        "        # 速度ベクトルの変化量\n",
        "        du = (u2 - u1) / dt\n",
        "        dv = (v2 - v1) / dt\n",
        "\n",
        "        # 加速度ベクトルの大きさ\n",
        "        accel_magnitude = np.sqrt(du**2 + dv**2)\n",
        "\n",
        "        # 加速度ベクトルの角度\n",
        "        accel_angle = np.arctan2(dv, du)\n",
        "        accel_angle_degrees = np.degrees(accel_angle)\n",
        "\n",
        "        accelerations.append((cx1, cy1, du, dv, accel_magnitude, accel_angle, accel_angle_degrees))\n",
        "    return accelerations\n",
        "\n",
        "# 実行例\n",
        "image1 = cv2.imread('opticalflow_val/0025.jpg')\n",
        "image2 = cv2.imread('opticalflow_val/0026.jpg')\n",
        "image3 = cv2.imread('opticalflow_val/0027.jpg')\n",
        "\n",
        "# 特徴点を検出\n",
        "keypoints = detect_keypoints(image1)\n",
        "\n",
        "# 各特徴点におけるオプティカルフローを計算\n",
        "results1 = compute_optical_flow_at_keypoints(image1, image2, keypoints)\n",
        "results2 = compute_optical_flow_at_keypoints(image2, image3, keypoints)\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 60.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 加速度ベクトルを計算\n",
        "accelerations = compute_acceleration(results1, results2, dt)\n",
        "\n",
        "# 結果の表示\n",
        "for (cx, cy, u, v, magnitude, angle, angle_degrees) in results1:\n",
        "    cv2.circle(image1, (cx, cy), 5, (0, 255, 0), -1)\n",
        "    point_st = (cx, cy)\n",
        "    point_ed = (cx + int(u)*10, cy + int(v)*10)\n",
        "    cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"KeyPoint ({cx}, {cy}): u={u}, v={v}, magnitude={magnitude}, angle (radians)={angle}, angle (degrees)={angle_degrees}\")\n",
        "\n",
        "for (cx, cy, u, v, magnitude, angle, angle_degrees) in results2:\n",
        "    cv2.circle(image2, (cx, cy), 5, (0, 255, 0), -1)\n",
        "    point_st = (cx, cy)\n",
        "    point_ed = (cx + int(u)*10, cy + int(v)*10)\n",
        "    cv2.line(image2, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"KeyPoint ({cx}, {cy}): u={u}, v={v}, magnitude={magnitude}, angle (radians)={angle}, angle (degrees)={angle_degrees}\")\n",
        "\n",
        "for (cx, cy, du, dv, magnitude, angle, angle_degrees) in accelerations:\n",
        "    cv2.circle(image2, (cx, cy), 5, (0, 255, 0), -1)\n",
        "    point_st = (cx, cy)\n",
        "    point_ed = (cx + int(du)*10, cy + int(dv)*10)\n",
        "    cv2.line(image2, point_st, point_ed, (0, 0, 255), 2)\n",
        "    print(f\"Acceleration ({cx}, {cy}): du={du}, dv={dv}, magnitude={magnitude}, angle (radians)={angle}, angle (degrees)={angle_degrees}\")\n",
        "\n",
        "# 結果の画像を表示または保存\n",
        "cv2_imshow(image1)\n",
        "cv2_imshow(image2)\n",
        "cv2_imshow(image3)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "aAYP7yXH0Oxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = cv2.imread('ball1.jpg')"
      ],
      "metadata": {
        "id": "rsUeZtQd4C45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = image1.shape[1]\n",
        "height = image1.shape[0]\n",
        "stride_H = 30\n",
        "stride_W = 30\n",
        "\n",
        "for h in range(0, height, stride_H):\n",
        "  for w in range(0, width, stride_W):\n",
        "    point_st = (w, h)\n",
        "    point_ed = (w + int(u), h + int(v))\n",
        "    cv2.line(image1, point_st, point_ed, (0, 0, 255), 2)\n",
        "\n",
        "cv2_imshow(image1)"
      ],
      "metadata": {
        "id": "s2F4dG9u37_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image2)"
      ],
      "metadata": {
        "id": "XQVZb9le2DOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最小浮動小数丸め誤差"
      ],
      "metadata": {
        "id": "8a93VKD85sqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: coding opticalflow\n",
        "\n",
        "# 最小浮動小数丸め誤差\n",
        "\n",
        "def compute_optical_flow(image1, image2):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 勾配の計算\n",
        "    Ix = cv2.Sobel(gray1, cv2.CV_64F, 1, 0, ksize=5)\n",
        "    Iy = cv2.Sobel(gray1, cv2.CV_64F, 0, 1, ksize=5)\n",
        "    It = cv2.subtract(gray2, gray1)\n",
        "\n",
        "    # Lucas-Kanade法による速度ベクトルの計算\n",
        "    window_size = 5\n",
        "    half_window = window_size // 2\n",
        "    u = np.zeros(gray1.shape)\n",
        "    v = np.zeros(gray1.shape)\n",
        "\n",
        "    for i in range(half_window, gray1.shape[0] - half_window):\n",
        "        for j in range(half_window, gray1.shape[1] - half_window):\n",
        "            Ix_window = Ix[i - half_window:i + half_window + 1, j - half_window:j + half_window + 1].flatten()\n",
        "            Iy_window = Iy[i - half_window:i + half_window + 1, j - half_window:j + half_window + 1].flatten()\n",
        "            It_window = It[i - half_window:i + half_window + 1, j - half_window:j + half_window + 1].flatten()\n",
        "\n",
        "            A = np.vstack((Ix_window, Iy_window)).T\n",
        "            b = -It_window\n",
        "\n",
        "            nu = np.linalg.lstsq(A, b, rcond=None)[0]\n",
        "            u[i, j] = nu[0]\n",
        "            v[i, j] = nu[1]\n",
        "\n",
        "    return u, v\n",
        "\n",
        "# 物体のセグメンテーションと重心計算（仮想的な例）\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = int(moments['m10'] / moments['m00'])\n",
        "        cy = int(moments['m01'] / moments['m00'])\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "# 実行例\n",
        "image1 = cv2.imread('demo/0001.jpg')\n",
        "image2 = cv2.imread('demo/0002.jpg')\n",
        "\n",
        "u, v = compute_optical_flow(image1, image2)\n",
        "cx, cy = segment_and_compute_centroid(image1)\n",
        "width = image1.shape[1]\n",
        "height = image1.shape[0]\n",
        "stride_H = 15\n",
        "stride_W = 15\n",
        "\n",
        "# 結果の表示\n",
        "cv2.circle(image1, (cx, cy), 5, (0, 255, 0), -1)\n",
        "point_st = (cx, cy)\n",
        "point_ed = (cx + int(u[cy,cx]), cy + int(v[cy,cx]))\n",
        "cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "\n",
        "for h in range(0, height, stride_H):\n",
        "  for w in range(0, width, stride_W):\n",
        "    point_st = (w, h)\n",
        "    point_ed = (w + int(u[h,w]), h + int(v[h,w]))\n",
        "    cv2.line(image1, point_st, point_ed, (0, 0, 255), 2)\n",
        "\n",
        "cv2_imshow(image1)\n",
        "\n",
        "\n",
        "print(\"Optical Flow (u, v):\", u, v)\n",
        "print(\"Centroid (cx, cy):\", cx, cy)\n"
      ],
      "metadata": {
        "id": "a41HfQJa9TQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = cv2.imread('ball1.jpg')\n",
        "image2 = cv2.imread('ball2.jpg')\n",
        "\n",
        "# u, v = compute_optical_flow(image1, image2)\n",
        "# cx, cy = segment_and_compute_centroid(image1)"
      ],
      "metadata": {
        "id": "wEzE64Sfu-VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = image1.shape[1]\n",
        "height = image1.shape[0]\n",
        "stride_H = 10\n",
        "stride_W = 10\n",
        "\n",
        "for h in range(0, height, stride_H):\n",
        "  for w in range(0, width, stride_W):\n",
        "    point_st = (w, h)\n",
        "    point_ed = (w + int(u[h,w]*100), h + int(v[h,w]*100))\n",
        "    cv2.line(image1, point_st, point_ed, (0, 0, 255), 2)\n",
        "\n",
        "cv2_imshow(image1)"
      ],
      "metadata": {
        "id": "_fea7XHouwAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total(x):\n",
        "  total = np.sum(x, axis=(0, 1))\n",
        "  return total\n",
        "\n",
        "totalU=total(u)\n",
        "totalV=total(v)"
      ],
      "metadata": {
        "id": "YgyMB-Y9tCxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_st = (cx, cy)\n",
        "point_ed = (cx + int(u[cy,cx]), cy + int(v[cy,cx]))\n",
        "cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "\n",
        "# point_st = (cx, cy)\n",
        "# point_ed = (cx + int(totalU*1000), cy + int(totalV*1000))\n",
        "# cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)"
      ],
      "metadata": {
        "id": "dpoR_AI0s6GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image1)"
      ],
      "metadata": {
        "id": "ZsVctwznnYWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_st = (cx, cy)\n",
        "point_ed = (cx + int(u[cy,cx]), cy + int(v[cy,cx]))\n",
        "cv2.line(image1, point_st, point_ed, (255, 0, 0), 1000)"
      ],
      "metadata": {
        "id": "Nbeqk5N1jcWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image1)"
      ],
      "metadata": {
        "id": "i4yKeYQeeWSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"outputUniformMotionDemo.mp4\")\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "\n",
        "codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "writer = cv2.VideoWriter('Opticaldemo.avi', codec, fps, (width, height))\n",
        "\n",
        "while(1):\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang*180/np.pi/2\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    frame2 = np.vstack((frame2, bgr))\n",
        "    writer.write(frame2)\n",
        "    frame2 = cv2.resize(frame2, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA)\n",
        "    cv2_imshow(frame2)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    prvs = next\n",
        "cap.release()\n",
        "writer.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Rw3BXgLmLJRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()\n",
        "writer.release()"
      ],
      "metadata": {
        "id": "HA_3Hrn0NJLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 物体の重心を抽出."
      ],
      "metadata": {
        "id": "yatuFR0EYUNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keypointsを加速度ベクトルのみにする."
      ],
      "metadata": {
        "id": "l0NMqWd288oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def create_gradient_mask(shape, center, radius):\n",
        "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
        "    mask = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
        "    mask = np.clip(mask, 0, radius)\n",
        "    mask = (radius - mask) / radius\n",
        "    mask = mask * 255  # マスクを0-255の範囲にスケーリング\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "# def apply_gradient_mask(image, mask):\n",
        "#     return cv2.multiply(image, mask.astype(np.uint8) / 255.0)\n",
        "def apply_gradient_mask(image, mask):\n",
        "    return (image * (mask.astype(np.uint8) / 255.0)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def compute_optical_flow_at_centroid(image1, image2, cx, cy):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # グラデーションマスクの作成\n",
        "    radius = 4  # マスクの半径\n",
        "    mask = create_gradient_mask(gray1.shape, (cx, cy), radius)\n",
        "\n",
        "    # グラデーションマスクを適用\n",
        "    masked_gray1 = apply_gradient_mask(gray1, mask)\n",
        "    masked_gray2 = apply_gradient_mask(gray2, mask)\n",
        "\n",
        "    cv2_imshow(masked_gray1)\n",
        "    cv2_imshow(masked_gray2)\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(masked_gray1, masked_gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    u = flow[cy, cx, 0]\n",
        "    v = flow[cy, cx, 1]\n",
        "\n",
        "    # 大きさの計算\n",
        "    magnitude = np.sqrt(u**2 + v**2)\n",
        "\n",
        "    # 角度の計算\n",
        "    angle = np.arctan2(v, u)  # ラジアン\n",
        "    angle_degrees = np.degrees(angle)  # 度に変換\n",
        "\n",
        "    return (cx, cy, u, v, magnitude, angle, angle_degrees)\n",
        "\n",
        "# 物体のセグメンテーションと重心計算（仮想的な例）\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = int(moments['m10'] / moments['m00'])\n",
        "        cy = int(moments['m01'] / moments['m00'])\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "# 加速度ベクトルを計算する関数\n",
        "def compute_acceleration(result1, result2, dt):\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "\n",
        "    # 速度ベクトルの変化量\n",
        "    du = (u2 - u1) / dt\n",
        "    dv = (v2 - v1) / dt\n",
        "\n",
        "    # 加速度ベクトルの大きさ\n",
        "    accel_magnitude = np.sqrt(du**2 + dv**2)\n",
        "\n",
        "    # 加速度ベクトルの角度\n",
        "    accel_angle = np.arctan2(dv, du)\n",
        "    accel_angle_degrees = np.degrees(accel_angle)\n",
        "\n",
        "    return (cx2, cy2, du, dv, accel_magnitude, accel_angle, accel_angle_degrees)\n",
        "\n",
        "# 実行例\n",
        "image1 = cv2.imread('opticalflow_val/0025.jpg')\n",
        "image2 = cv2.imread('opticalflow_val/0026.jpg')\n",
        "image3 = cv2.imread('opticalflow_val/0027.jpg')\n",
        "\n",
        "# 各画像の重心を計算\n",
        "cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "# 重心におけるオプティカルフローを計算\n",
        "result1 = compute_optical_flow_at_centroid(image1, image2, cx1, cy1)\n",
        "result2 = compute_optical_flow_at_centroid(image2, image3, cx2, cy2)\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 60.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 加速度ベクトルを計算\n",
        "acceleration = compute_acceleration(result1, result2, dt)\n",
        "\n",
        "# 結果の表示\n",
        "(cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "(cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "(cx3, cy3, du, dv, accel_magnitude, accel_angle, accel_angle_degrees) = acceleration\n",
        "\n",
        "# image1 にオプティカルフローを描画\n",
        "cv2.circle(image1, (cx1, cy1), 5, (0, 255, 0), -1)\n",
        "point_st = (cx1, cy1)\n",
        "point_ed = (cx1 + int(u1*10**10), cy1 + int(v1*10**10))\n",
        "cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "print(f\"Frame 1 to Frame 2: KeyPoint ({cx1}, {cy1}): u={u1}, v={v1}, magnitude={mag1}, angle (radians)={ang1}, angle (degrees)={ang_deg1}\")\n",
        "\n",
        "# image2 にオプティカルフローを描画\n",
        "cv2.circle(image2, (cx2, cy2), 5, (0, 255, 0), -1)\n",
        "point_st = (cx2, cy2)\n",
        "point_ed = (cx2 + int(u2*10**12), cy2 + int(v2*10**12))\n",
        "cv2.line(image2, point_st, point_ed, (255, 0, 0), 2)\n",
        "print(f\"Frame 2 to Frame 3: KeyPoint ({cx2}, {cy2}): u={u2}, v={v2}, magnitude={mag2}, angle (radians)={ang2}, angle (degrees)={ang_deg2}\")\n",
        "\n",
        "# image2 に加速度ベクトルを描画\n",
        "cv2.circle(image2, (cx2, cy2), 5, (0, 255, 255), -1)  # Yellow circle for acceleration\n",
        "point_st = (cx2, cy2)\n",
        "point_ed = (cx2 + int(du*10**10), cy2 + int(dv*10**10))\n",
        "cv2.line(image2, point_st, point_ed, (0, 0, 255), 2)\n",
        "print(f\"Acceleration: KeyPoint ({cx3}, {cy3}): du={du}, dv={dv}, magnitude={accel_magnitude}, angle (radians)={accel_angle}, angle (degrees)={accel_angle_degrees}\")\n",
        "\n",
        "# 結果の画像を表示または保存\n",
        "cv2_imshow(image1)\n",
        "cv2_imshow(image2)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "OOLzxIcu88Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 全フレームに適用"
      ],
      "metadata": {
        "id": "K_x0XlCmL_TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def create_gradient_mask(shape, center, radius):\n",
        "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
        "    mask = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
        "    mask = np.clip(mask, 0, radius)\n",
        "    mask = (radius - mask) / radius\n",
        "    mask = mask * 255  # マスクを0-255の範囲にスケーリング\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "def apply_gradient_mask(image, mask):\n",
        "    return (image * (mask.astype(np.float32) / 255.0)).astype(np.uint8)\n",
        "\n",
        "def compute_optical_flow_at_centroid(image1, image2, cx, cy, prev_cx, prev_cy):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # グラデーションマスクの作成\n",
        "    radius = 50  # マスクの半径\n",
        "    mask = create_gradient_mask(gray1.shape, (prev_cx, prev_cy), radius)\n",
        "\n",
        "    # グラデーションマスクを適用\n",
        "    masked_gray1 = apply_gradient_mask(gray1, mask)\n",
        "    masked_gray2 = apply_gradient_mask(gray2, mask)\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(masked_gray1, masked_gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    u = flow[cy, cx, 0]\n",
        "    v = flow[cy, cx, 1]\n",
        "\n",
        "    # 大きさの計算\n",
        "    magnitude = np.sqrt(u**2 + v**2)\n",
        "\n",
        "    # 角度の計算\n",
        "    angle = np.arctan2(v, u)  # ラジアン\n",
        "    angle_degrees = np.degrees(angle)  # 度に変換\n",
        "\n",
        "    return (cx, cy, u, v, magnitude, angle, angle_degrees)\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = int(moments['m10'] / moments['m00'])\n",
        "        cy = int(moments['m01'] / moments['m00'])\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "def compute_acceleration(result1, result2, dt):\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "\n",
        "    # 速度ベクトルの変化量\n",
        "    du = (u2 - u1) / dt\n",
        "    dv = (v2 - v1) / dt\n",
        "\n",
        "    # 加速度ベクトルの大きさ\n",
        "    accel_magnitude = np.sqrt(du**2 + dv**2)\n",
        "\n",
        "    # 加速度ベクトルの角度\n",
        "    accel_angle = np.arctan2(dv, du)\n",
        "    accel_angle_degrees = np.degrees(accel_angle)\n",
        "\n",
        "    return (cx2, cy2, du, dv, accel_magnitude, accel_angle, accel_angle_degrees)\n",
        "\n",
        "# 画像が格納されているフォルダのパス\n",
        "image_folder = 'newmethod'\n",
        "\n",
        "# 画像ファイルをすべて取得\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 30.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 初期フレームの重心を計算\n",
        "initial_frame = cv2.imread(image_files[0])\n",
        "prev_cx, prev_cy = segment_and_compute_centroid(initial_frame)\n",
        "\n",
        "# すべてのフレームを処理\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "\n",
        "    # 各画像の重心を計算\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "    # 重心におけるオプティカルフローを計算\n",
        "    result1 = compute_optical_flow_at_centroid(image1, image2, cx1, cy1, prev_cx, prev_cy)\n",
        "    result2 = compute_optical_flow_at_centroid(image2, image3, cx2, cy2, cx1, cy1)\n",
        "\n",
        "    # 加速度ベクトルを計算\n",
        "    acceleration = compute_acceleration(result1, result2, dt)\n",
        "\n",
        "    # 結果の表示\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "    (cx3, cy3, du, dv, accel_magnitude, accel_angle, accel_angle_degrees) = acceleration\n",
        "\n",
        "    # image1 にオプティカルフローを描画\n",
        "    cv2.circle(image1, (cx1, cy1), 5, (0, 255, 0), -1)\n",
        "    point_st = (cx1, cy1)\n",
        "    point_ed = (cx1 + int(u1 * 10 ** 7), cy1 + int(v1 * 10 ** 7))  # スケールを適切に調整\n",
        "    cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"Frame {i+1} to Frame {i+2}: KeyPoint ({cx1}, {cy1}): u={u1}, v={v1}, magnitude={mag1}, angle (radians)={ang1}, angle (degrees)={ang_deg1}\")\n",
        "\n",
        "    # image2 にオプティカルフローを描画\n",
        "    cv2.circle(image2, (cx2, cy2), 5, (0, 255, 0), -1)\n",
        "    point_st = (cx2, cy2)\n",
        "    point_ed = (cx2 + int(u2 * 10 ** 7), cy2 + int(v2 * 10 ** 7))  # スケールを適切に調整\n",
        "    cv2.line(image2, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"Frame {i+2} to Frame {i+3}: KeyPoint ({cx2}, {cy2}): u={u2}, v={v2}, magnitude={mag2}, angle (radians)={ang2}, angle (degrees)={ang_deg2}\")\n",
        "\n",
        "    # image2 に加速度ベクトルを描画\n",
        "    cv2.circle(image2, (cx2, cy2), 5, (0, 255, 255), -1)  # Yellow circle for acceleration\n",
        "    point_st = (cx2, cy2)\n",
        "    point_ed = (cx2 + int(du * 10 ** 6), cy2 + int(dv * 10 ** 6))  # スケールを適切に調整\n",
        "    cv2.line(image2, point_st, point_ed, (0, 0, 255), 2)\n",
        "    print(f\"Acceleration: KeyPoint ({cx3}, {cy3}): du={du}, dv={dv}, magnitude={accel_magnitude}, angle (radians)={accel_angle}, angle (degrees)={accel_angle_degrees}\")\n",
        "\n",
        "    # 結果の画像を表示または保存\n",
        "    # print(f'Result Frame {i+1}')\n",
        "    # cv2_imshow(image1)\n",
        "    print(f'Result Frame {i+2}')\n",
        "    cv2_imshow(image2)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # 次のフレームのために重心を更新\n",
        "    prev_cx, prev_cy = cx1, cy1\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "rjcZR6gv88Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# シミュレーションパラメータ\n",
        "num_frames = 60\n",
        "frame_size = (200, 200)\n",
        "radius = 50\n",
        "center = (100, 100)\n",
        "omega = 2 * np.pi / num_frames  # 一周するための角速度\n",
        "\n",
        "# フレームの生成\n",
        "frames = []\n",
        "for t in range(num_frames):\n",
        "    frame = np.zeros(frame_size, dtype=np.uint8)\n",
        "    x = int(center[0] + radius * np.cos(omega * t))\n",
        "    y = int(center[1] + radius * np.sin(omega * t))\n",
        "    cv2.circle(frame, (x, y), 5, 255, -1)\n",
        "    frames.append(frame)\n",
        "\n",
        "# 重心の検出と追跡\n",
        "lk_params = dict(winSize=(5, 5), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "p0 = np.array([[center]], dtype=np.float32)  # 初期位置を重心に設定\n",
        "\n",
        "# 特徴点の追跡\n",
        "for i in range(1, num_frames):\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(frames[i-1], frames[i], p0, None, **lk_params)\n",
        "    if p1 is not None:\n",
        "        p0 = p1\n",
        "    else:\n",
        "        p0 = np.array([[center]], dtype=np.float32)  # トラッキングが失敗した場合、中心に戻す\n",
        "\n",
        "    # ベクトルの表示\n",
        "    vis = cv2.cvtColor(frames[i], cv2.COLOR_GRAY2BGR)\n",
        "    for pt in p1:\n",
        "        x, y = pt.ravel()\n",
        "        cv2.circle(vis, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
        "\n",
        "    print('Feature Tracking')\n",
        "    cv2_imshow(vis)\n",
        "    cv2.waitKey(50)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "1GATJd_1SRHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 円運動を行う物体の加速度オプティカルフロー"
      ],
      "metadata": {
        "id": "yvTcM7pwmQMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# シミュレーションパラメータ\n",
        "num_frames = 60\n",
        "frame_size = (200, 200)\n",
        "radius = 50\n",
        "center = (100, 100)\n",
        "omega = 2 * np.pi / num_frames  # 一周するための角速度\n",
        "\n",
        "# フレームの生成\n",
        "frames = []\n",
        "for t in range(num_frames):\n",
        "    frame = np.zeros(frame_size, dtype=np.uint8)\n",
        "    x = int(center[0] + radius * np.cos(omega * t))\n",
        "    y = int(center[1] + radius * np.sin(omega * t))\n",
        "    cv2.circle(frame, (x, y), 5, 255, -1)\n",
        "    frames.append(frame)\n",
        "\n",
        "# フレームの表示（確認用）\n",
        "for frame in frames:\n",
        "    print('Circular Motion')\n",
        "    cv2_imshow(frame)\n",
        "    cv2.waitKey(100)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "e4gfGT6_Gmmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# オプティカルフローの計算と可視化\n",
        "for i in range(num_frames - 1):\n",
        "    frame1 = frames[i]\n",
        "    frame2 = frames[i + 1]\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # 結果の可視化\n",
        "    hsv = np.zeros_like(cv2.cvtColor(frame1, cv2.COLOR_GRAY2BGR))\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    print('Optical Flow')\n",
        "    cv2_imshow(rgb)\n",
        "    cv2.waitKey(100)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "kHXx1h5xmnyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加速度の計算と可視化\n",
        "accelerations = []\n",
        "for i in range(num_frames - 2):\n",
        "    frame1 = frames[i]\n",
        "    frame2 = frames[i + 1]\n",
        "    frame3 = frames[i + 2]\n",
        "\n",
        "    # 速度ベクトルの計算\n",
        "    flow1 = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    flow2 = cv2.calcOpticalFlowFarneback(frame2, frame3, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # 加速度ベクトルの計算\n",
        "    acceleration = flow2 - flow1\n",
        "    accelerations.append(acceleration)\n",
        "\n",
        "    # 結果の可視化\n",
        "    hsv = np.zeros_like(cv2.cvtColor(frame1, cv2.COLOR_GRAY2BGR))\n",
        "    mag, ang = cv2.cartToPolar(acceleration[..., 0], acceleration[..., 1])\n",
        "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    print(i)\n",
        "    cv2_imshow(rgb)\n",
        "    cv2.waitKey(100)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "72tAb2hKm7Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# シミュレーションパラメータ\n",
        "num_frames = 60\n",
        "frame_size = (200, 200)\n",
        "radius = 50\n",
        "center = (100, 100)\n",
        "omega = 2 * np.pi / num_frames  # 一周するための角速度\n",
        "\n",
        "# フレームの生成\n",
        "frames = []\n",
        "for t in range(num_frames):\n",
        "    frame = np.zeros(frame_size, dtype=np.uint8)\n",
        "    x = int(center[0] + radius * np.cos(omega * t))\n",
        "    y = int(center[1] + radius * np.sin(omega * t))\n",
        "    cv2.circle(frame, (x, y), 5, 255, -1)\n",
        "    frames.append(frame)\n",
        "\n",
        "# フレームの表示（確認用）\n",
        "for frame in frames:\n",
        "    cv2_imshow(frame)\n",
        "    cv2.waitKey(100)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "AdEQs9zmoIgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# オプティカルフローの計算と可視化\n",
        "for i in range(num_frames - 1):\n",
        "    frame1 = frames[i]\n",
        "    frame2 = frames[i + 1]\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # 結果の可視化\n",
        "    hsv = np.zeros_like(cv2.cvtColor(frame1, cv2.COLOR_GRAY2BGR))\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    cv2_imshow(rgb)\n",
        "    cv2.waitKey(100)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "vJnJ63i2pLD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# シミュレーションパラメータ\n",
        "num_frames = 120  # フレーム数を増やしてフレーム間の変位を小さくする\n",
        "frame_size = (200, 200)\n",
        "radius = 50\n",
        "center = (100, 100)\n",
        "omega = 2 * np.pi / num_frames  # 一周するための角速度\n",
        "\n",
        "# フレームの生成\n",
        "frames = []\n",
        "for t in range(num_frames):\n",
        "    frame = np.zeros(frame_size, dtype=np.uint8)\n",
        "    x = int(center[0] + radius * np.cos(omega * t))\n",
        "    y = int(center[1] + radius * np.sin(omega * t))\n",
        "    cv2.circle(frame, (x, y), 5, 255, -1)\n",
        "    frames.append(frame)\n",
        "\n",
        "# フレームの表示（確認用）\n",
        "for frame in frames:\n",
        "    cv2_imshow(frame)\n",
        "    cv2.waitKey(50)  # フレームレートを上げる\n",
        "\n",
        "# オプティカルフローの計算とベクトル表示\n",
        "for i in range(num_frames - 1):\n",
        "    frame1 = frames[i]\n",
        "    frame2 = frames[i + 1]\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # ベクトルの表示\n",
        "    h, w = frame1.shape\n",
        "    step = 16\n",
        "    y, x = np.mgrid[step/2:h:step, step/2:w:step].astype(np.int64)\n",
        "    fx, fy = flow[y, x].T\n",
        "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines + 0.5)\n",
        "    vis = cv2.cvtColor(frame1, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
        "\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
        "\n",
        "    cv2_imshow(vis)\n",
        "    cv2.waitKey(50)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# 特徴点の検出と追跡\n",
        "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
        "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# 初期フレームの特徴点を検出\n",
        "p0 = cv2.goodFeaturesToTrack(frames[0], mask=None, **feature_params)\n",
        "\n",
        "# 特徴点の追跡\n",
        "for i in range(1, num_frames):\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(frames[i-1], frames[i], p0, None, **lk_params)\n",
        "\n",
        "    # ベクトルの表示\n",
        "    vis = cv2.cvtColor(frames[i], cv2.COLOR_GRAY2BGR)\n",
        "    for pt in p1:\n",
        "        x, y = pt.ravel()\n",
        "        cv2.circle(vis, (x, y), 5, (0, 255, 0), -1)\n",
        "\n",
        "    cv2_imshow(vis)\n",
        "    cv2.waitKey(50)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "2NsMKn1hpTG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def create_gradient_mask(shape, center, radius):\n",
        "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
        "    mask = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
        "    mask = np.clip(mask, 0, radius)\n",
        "    mask = (radius - mask) / radius\n",
        "    mask = mask * 255  # マスクを0-255の範囲にスケーリング\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "def apply_gradient_mask(image, mask):\n",
        "    return (image * (mask.astype(np.float32) / 255.0)).astype(np.uint8)\n",
        "\n",
        "def compute_optical_flow_at_centroid(image1, image2, cx, cy):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # グラデーションマスクの作成\n",
        "    radius = 50  # マスクの半径\n",
        "    mask = create_gradient_mask(gray1.shape, (cx, cy), radius)\n",
        "\n",
        "    # グラデーションマスクを適用\n",
        "    masked_gray1 = apply_gradient_mask(gray1, mask)\n",
        "    masked_gray2 = apply_gradient_mask(gray2, mask)\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(masked_gray1, masked_gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    # サブピクセル精度での流れを取得\n",
        "    u = cv2.getRectSubPix(flow[..., 0], (1, 1), (float(cx), float(cy)))[0, 0]\n",
        "    v = cv2.getRectSubPix(flow[..., 1], (1, 1), (float(cx), float(cy)))[0, 0]\n",
        "\n",
        "    # 大きさの計算\n",
        "    magnitude = np.sqrt(u**2 + v**2)\n",
        "\n",
        "    # 角度の計算\n",
        "    angle = np.arctan2(v, u)  # ラジアン\n",
        "    angle_degrees = np.degrees(angle)  # 度に変換\n",
        "\n",
        "    return (cx, cy, u, v, magnitude, angle, angle_degrees)\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "def compute_acceleration(result1, result2, dt):\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "\n",
        "    # 速度ベクトルの変化量\n",
        "    du = (u2 - u1) / dt\n",
        "    dv = (v2 - v1) / dt\n",
        "\n",
        "    # 加速度ベクトルの大きさ\n",
        "    accel_magnitude = np.sqrt(du**2 + dv**2)\n",
        "\n",
        "    # 加速度ベクトルの角度\n",
        "    accel_angle = np.arctan2(dv, du)\n",
        "    accel_angle_degrees = np.degrees(accel_angle)\n",
        "\n",
        "    return (cx2, cy2, du, dv, accel_magnitude, accel_angle, accel_angle_degrees)\n",
        "\n",
        "# 画像が格納されているフォルダのパス\n",
        "image_folder = 'newmethod'\n",
        "\n",
        "# 画像ファイルをすべて取得\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 30.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 初期フレームの重心を計算\n",
        "initial_frame = cv2.imread(image_files[0])\n",
        "prev_cx, prev_cy = segment_and_compute_centroid(initial_frame)\n",
        "\n",
        "# すべてのフレームを処理\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "\n",
        "    # 各画像の重心を計算\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "    # 重心におけるオプティカルフローを計算\n",
        "    result1 = compute_optical_flow_at_centroid(image1, image2, cx1, cy1)\n",
        "    result2 = compute_optical_flow_at_centroid(image2, image3, cx2, cy2)\n",
        "\n",
        "    # 加速度ベクトルを計算\n",
        "    acceleration = compute_acceleration(result1, result2, dt)\n",
        "\n",
        "    # 結果の表示\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "    (cx3, cy3, du, dv, accel_magnitude, accel_angle, accel_angle_degrees) = acceleration\n",
        "\n",
        "    # image1 にオプティカルフローを描画\n",
        "    cv2.circle(image1, (int(cx1), int(cy1)), 5, (0, 255, 0), -1)\n",
        "    point_st = (int(cx1), int(cy1))\n",
        "    point_ed = (int(cx1 + u1 * 10), int(cy1 + v1 * 10))  # スケールを適切に調整\n",
        "    cv2.line(image1, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"Frame {i+1} to Frame {i+2}: KeyPoint ({cx1}, {cy1}): u={u1}, v={v1}, magnitude={mag1}, angle (radians)={ang1}, angle (degrees)={ang_deg1}\")\n",
        "\n",
        "    # image2 にオプティカルフローを描画\n",
        "    cv2.circle(image2, (int(cx2), int(cy2)), 5, (0, 255, 0), -1)\n",
        "    point_st = (int(cx2), int(cy2))\n",
        "    point_ed = (int(cx2 + u2 * 10), int(cy2 + v2 * 10))  # スケールを適切に調整\n",
        "    cv2.line(image2, point_st, point_ed, (255, 0, 0), 2)\n",
        "    print(f\"Frame {i+2} to Frame {i+3}: KeyPoint ({cx2}, {cy2}): u={u2}, v={v2}, magnitude={mag2}, angle (radians)={ang2}, angle (degrees)={ang_deg2}\")\n",
        "\n",
        "    # image2 に加速度ベクトルを描画\n",
        "    cv2.circle(image2, (int(cx2), int(cy2)), 5, (0, 255, 255), -1)  # Yellow circle for acceleration\n",
        "    point_st = (int(cx2), int(cy2))\n",
        "    point_ed = (int(cx2 + du * 10), int(cy2 + dv * 10))  # スケールを適切に調整\n",
        "    cv2.line(image2, point_st, point_ed, (0, 0, 255), 2)\n",
        "    print(f\"Acceleration: KeyPoint ({cx3}, {cy3}): du={du}, dv={dv}, magnitude={accel_magnitude}, angle (radians)={accel_angle}, angle (degrees)={accel_angle_degrees}\")\n",
        "\n",
        "    # 結果の画像を表示または保存\n",
        "    # print(f'Result Frame {i+1}')\n",
        "    # cv2_imshow(image1)\n",
        "    print(f'Result Frame {i+2}')\n",
        "    cv2_imshow(image2)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # 次のフレームのために重心を更新\n",
        "    prev_cx, prev_cy = cx2, cy2\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "OdpSQ8bJWk9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 重心座標を浮動小数点として計算."
      ],
      "metadata": {
        "id": "42Av0F8pPSJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def create_gradient_mask(shape, center, radius):\n",
        "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
        "    mask = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
        "    mask = np.clip(mask, 0, radius)\n",
        "    mask = (radius - mask) / radius\n",
        "    mask = mask * 255  # マスクを0-255の範囲にスケーリング\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "def apply_gradient_mask(image, mask):\n",
        "    return (image * (mask.astype(np.float32) / 255.0)).astype(np.uint8)\n",
        "\n",
        "def compute_optical_flow_at_centroid(image1, image2, cx, cy):\n",
        "    # 画像の前処理\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # グラデーションマスクの作成\n",
        "    radius = 50  # マスクの半径\n",
        "    mask = create_gradient_mask(gray1.shape, (cx, cy), radius)\n",
        "\n",
        "    # グラデーションマスクを適用\n",
        "    masked_gray1 = apply_gradient_mask(gray1, mask)\n",
        "    masked_gray2 = apply_gradient_mask(gray2, mask)\n",
        "\n",
        "    # オプティカルフローの計算\n",
        "    flow = cv2.calcOpticalFlowFarneback(masked_gray1, masked_gray2, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    # サブピクセル精度での流れを取得\n",
        "    u = cv2.getRectSubPix(flow[..., 0], (1, 1), (float(cx), float(cy)))[0, 0]\n",
        "    v = cv2.getRectSubPix(flow[..., 1], (1, 1), (float(cx), float(cy)))[0, 0]\n",
        "\n",
        "    # 大きさの計算\n",
        "    magnitude = np.sqrt(u**2 + v**2)\n",
        "\n",
        "    # 角度の計算\n",
        "    angle = np.arctan2(v, u)  # ラジアン\n",
        "    angle_degrees = np.degrees(angle)  # 度に変換\n",
        "\n",
        "    return (cx, cy, u, v, magnitude, angle, angle_degrees)\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "def compute_acceleration(result1, result2, dt):\n",
        "    (cx1, cy1, u1, v1, mag1, ang1, ang_deg1) = result1\n",
        "    (cx2, cy2, u2, v2, mag2, ang2, ang_deg2) = result2\n",
        "\n",
        "    # 速度ベクトルの変化量\n",
        "    du = (u2 - u1) / dt\n",
        "    dv = (v2 - v1) / dt\n",
        "\n",
        "    # 加速度ベクトルの大きさ\n",
        "    accel_magnitude = np.sqrt(du**2 + dv**2)\n",
        "\n",
        "    # 加速度ベクトルの角度\n",
        "    accel_angle = np.arctan2(dv, du)\n",
        "    accel_angle_degrees = np.degrees(accel_angle)\n",
        "\n",
        "    return (cx2, cy2, du, dv, accel_magnitude, accel_angle, accel_angle_degrees)\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "# 画像が格納されているフォルダのパス\n",
        "image_folder = 'newmethod'\n",
        "\n",
        "# 画像ファイルをすべて取得\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 30.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 初期フレームの重心を計算\n",
        "initial_frame = cv2.imread(image_files[0])\n",
        "prev_cx, prev_cy = segment_and_compute_centroid(initial_frame)\n",
        "\n",
        "# 結果を格納するリスト\n",
        "results = []\n",
        "\n",
        "# すべてのフレームを処理\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "\n",
        "    # 各画像の重心を計算\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "    # 重心におけるオプティカルフローを計算\n",
        "    result1 = compute_optical_flow_at_centroid(image1, image2, cx1, cy1)\n",
        "    result2 = compute_optical_flow_at_centroid(image2, image3, cx2, cy2)\n",
        "\n",
        "    # 加速度ベクトルを計算\n",
        "    acceleration = compute_acceleration(result1, result2, dt)\n",
        "\n",
        "    # 理論値を計算\n",
        "    theoX, theoY, theoVx, theoVy, theoAx, theoAy = theoretical_values(i+1, 200, 1.0)\n",
        "\n",
        "    # 結果をリストに追加\n",
        "    results.append([i+1, cx1, cy1, result1[2], result1[3], acceleration[2], acceleration[3],\n",
        "                    theoX, theoY, theoVx, theoVy, theoAx, theoAy])\n",
        "\n",
        "    # 次のフレームのために重心を更新\n",
        "    prev_cx, prev_cy = cx2, cy2\n",
        "\n",
        "# 結果をデータフレームに変換してCSVファイルに保存\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay', 'TheoX', 'TheoY', 'TheoVx', 'TheoVy', 'TheoAx', 'TheoAy'])\n",
        "df.to_csv('optical_flow_results.csv', index=False)\n",
        "\n",
        "print(\"結果をoptical_flow_results.csvに保存しました。\")\n"
      ],
      "metadata": {
        "id": "C3ZOjL7WPR-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 重心と座標を用いて加速度オプティカルフローを求める."
      ],
      "metadata": {
        "id": "mrpBEbGRbYoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "def compute_velocity_and_acceleration(centroid1, centroid2, centroid3, dt):\n",
        "    cx1, cy1 = centroid1\n",
        "    cx2, cy2 = centroid2\n",
        "    cx3, cy3 = centroid3\n",
        "\n",
        "    # 速度の計算\n",
        "    Vx1 = (cx2 - cx1) / dt\n",
        "    Vy1 = (cy2 - cy1) / dt\n",
        "    Vx2 = (cx3 - cx2) / dt\n",
        "    Vy2 = (cy3 - cy2) / dt\n",
        "\n",
        "    # 加速度の計算\n",
        "    Ax = (Vx2 - Vx1) / dt\n",
        "    Ay = (Vy2 - Vy1) / dt\n",
        "\n",
        "    return Vx1, Vy1, Ax, Ay\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "# 画像が格納されているフォルダのパス\n",
        "image_folder = 'newmethod'\n",
        "\n",
        "# 画像ファイルをすべて取得\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 30.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 結果を格納するリスト\n",
        "results = []\n",
        "\n",
        "# すべてのフレームを処理\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "\n",
        "    # 各画像の重心を計算\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "    # 重心の座標から速度と加速度を計算\n",
        "    Vx, Vy, Ax, Ay = compute_velocity_and_acceleration((cx1, cy1), (cx2, cy2), (cx3, cy3), dt)\n",
        "\n",
        "    # 理論値を計算\n",
        "    theoX, theoY, theoVx, theoVy, theoAx, theoAy = theoretical_values(i+1, 200, 1.0)\n",
        "\n",
        "    # 結果をリストに追加\n",
        "    results.append([i+1, cx1, cy1, Vx, Vy, Ax, Ay, theoX, theoY, theoVx, theoVy, theoAx, theoAy])\n",
        "\n",
        "# 結果をデータフレームに変換してCSVファイルに保存\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay', 'TheoX', 'TheoY', 'TheoVx', 'TheoVy', 'TheoAx', 'TheoAy'])\n",
        "df.to_csv('centroid_based_acceleration.csv', index=False)\n",
        "\n",
        "print(\"結果をcentroid_based_acceleration.csvに保存しました。\")\n"
      ],
      "metadata": {
        "id": "A5yx6UiLPp3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    # 簡単な二値化によるセグメンテーション\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 重心の計算\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "\n",
        "    return cx, cy\n",
        "\n",
        "def compute_velocity_and_acceleration(centroid1, centroid2, centroid3, dt):\n",
        "    cx1, cy1 = centroid1\n",
        "    cx2, cy2 = centroid2\n",
        "    cx3, cy3 = centroid3\n",
        "\n",
        "    # 速度の計算\n",
        "    Vx1 = (cx2 - cx1) / dt\n",
        "    Vy1 = (cy2 - cy1) / dt\n",
        "    Vx2 = (cx3 - cx2) / dt\n",
        "    Vy2 = (cy3 - cy2) / dt\n",
        "\n",
        "    # 加速度の計算\n",
        "    Ax = (Vx2 - Vx1) / dt\n",
        "    Ay = (Vy2 - Vy1) / dt\n",
        "\n",
        "    return Vx1, Vy1, Ax, Ay\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "# 画像が格納されているフォルダのパス\n",
        "image_folder = 'newmethod'\n",
        "\n",
        "# 画像ファイルをすべて取得\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "# フレーム間の時間差（秒）\n",
        "dt = 1 / 30.0  # 例えば、30 FPS の動画の場合\n",
        "\n",
        "# 結果を格納するリスト\n",
        "results = []\n",
        "\n",
        "# すべてのフレームを処理\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "\n",
        "    # 各画像の重心を計算\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "\n",
        "    # 重心の座標から速度と加速度を計算\n",
        "    Vx, Vy, Ax, Ay = compute_velocity_and_acceleration((cx1, cy1), (cx2, cy2), (cx3, cy3), dt)\n",
        "\n",
        "    # 加速度ベクトルを描画\n",
        "    start_point = (int(cx2), int(cy2))\n",
        "    end_point = (int(cx2 + Ax * 10), int(cy2 + Ay * 10))\n",
        "    cv2.arrowedLine(image2, start_point, end_point, (0, 0, 255), 2)\n",
        "\n",
        "    # 結果をリストに追加\n",
        "    results.append([i+1, cx1, cy1, Vx, Vy, Ax, Ay])\n",
        "\n",
        "    # 描画されたフレームを保存\n",
        "    cv2.imwrite(f'output_frame_{i+1}.png', image2)\n",
        "\n",
        "# 結果をデータフレームに変換してCSVファイルに保存\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay'])\n",
        "df.to_csv('centroid_based_acceleration.csv', index=False)\n",
        "\n",
        "print(\"結果をcentroid_based_acceleration.csvに保存し、フレームを保存しました。\")\n"
      ],
      "metadata": {
        "id": "W1C5qCKAbVHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "    return cx, cy\n",
        "\n",
        "def compute_velocity_and_acceleration(centroid1, centroid2, centroid3, dt):\n",
        "    cx1, cy1 = centroid1\n",
        "    cx2, cy2 = centroid2\n",
        "    cx3, cy3 = centroid3\n",
        "    # Vx1 = (cx2 - cx1) / dt\n",
        "    # Vy1 = (cy2 - cy1) / dt\n",
        "    # Vx2 = (cx3 - cx2) / dt\n",
        "    # Vy2 = (cy3 - cy2) / dt\n",
        "    # Ax = (Vx2 - Vx1) / dt\n",
        "    # Ay = (Vy2 - Vy1) / dt\n",
        "    Vx1 = (cx2 - cx1)\n",
        "    Vy1 = (cy2 - cy1)\n",
        "    Vx2 = (cx3 - cx2)\n",
        "    Vy2 = (cy3 - cy2)\n",
        "    Ax = (Vx2 - Vx1)\n",
        "    Ay = (Vy2 - Vy1)\n",
        "    return Vx1, Vy1, Ax, Ay\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "image_folder = 'newmethod'\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "dt = 1 / 30.0\n",
        "\n",
        "results = []\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "    Vx, Vy, Ax, Ay = compute_velocity_and_acceleration((cx1, cy1), (cx2, cy2), (cx3, cy3), dt)\n",
        "    results.append([i+1, cx1, cy1, Vx, Vy, Ax, Ay])\n",
        "\n",
        "# データを平滑化\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay'])\n",
        "df['Vx_smooth'] = savgol_filter(df['Vx'], window_length=5, polyorder=2)\n",
        "df['Vy_smooth'] = savgol_filter(df['Vy'], window_length=5, polyorder=2)\n",
        "\n",
        "# 平滑化後の速度から加速度を再計算\n",
        "df['Ax_smooth'] = df['Vx_smooth'].diff()\n",
        "df['Ay_smooth'] = df['Vy_smooth'].diff()\n",
        "# NaN値を0に置換\n",
        "df.fillna(0, inplace=True)\n",
        "# 各フレームに加速度ベクトルを描画\n",
        "for i in range(len(image_files) - 2):\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    cx2, cy2 = df.loc[i, ['X', 'Y']]\n",
        "    Ax, Ay = df.loc[i, ['Ax_smooth', 'Ay_smooth']]\n",
        "    start_point = (int(cx2), int(cy2))\n",
        "    end_point = (int(cx2 + Ax * 10), int(cy2 + Ay * 10))\n",
        "    cv2.arrowedLine(image2, start_point, end_point, (0, 0, 255), 2)\n",
        "    cv2.imwrite(f'outputV2_frame_{i+1}.png', image2)\n",
        "\n",
        "df.to_csv('centroid_based_acceleration_smoothV3.csv', index=False)\n",
        "print(\"結果をcentroid_based_acceleration_smooth.csvに保存し、フレームを保存しました。\")\n"
      ],
      "metadata": {
        "id": "gx6F1k04rGA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('centroid_based_acceleration_smoothV2.csv', index=False)"
      ],
      "metadata": {
        "id": "rpyZrnXjsLYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install filterpy pandas"
      ],
      "metadata": {
        "id": "izSB8Kx65ge_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.signal import savgol_filter, butter, filtfilt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "def initialize_kalman_filter():\n",
        "    \"\"\"\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    kf = KalmanFilter(dim_x=2, dim_z=1)\n",
        "    kf.F = np.array([[1, 1], [0, 1]])  # 状態遷移行列\n",
        "    kf.H = np.array([[1, 0]])          # 観測行列\n",
        "    kf.P *= 1000.                      # 誤差共分散行列の初期設定\n",
        "    kf.R = np.array([[5]])             # 観測ノイズの共分散\n",
        "    kf.Q = np.array([[1, 0], [0, 1]])  # プロセスノイズの共分散\n",
        "    kf.x = np.array([[0], [0]])        # 初期状態\n",
        "    return kf\n",
        "\n",
        "def kalman_filter_acceleration(data):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      data:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    kf = initialize_kalman_filter()\n",
        "    filtered_data = []\n",
        "    for measurement in data:\n",
        "        kf.predict()\n",
        "        kf.update([measurement])\n",
        "        filtered_data.append(kf.x[0][0])\n",
        "    return np.array(filtered_data)\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      image:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "    return cx, cy\n",
        "\n",
        "def compute_velocity_and_acceleration(centroid1, centroid2, centroid3, dt):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      centroid1:\n",
        "      centroid2:\n",
        "      centroid3:\n",
        "      dt:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    cx1, cy1 = centroid1\n",
        "    cx2, cy2 = centroid2\n",
        "    cx3, cy3 = centroid3\n",
        "\n",
        "    # Vx1 = (cx2 - cx1) / dt\n",
        "    # Vy1 = (cy2 - cy1) / dt\n",
        "    # Vx2 = (cx3 - cx2) / dt\n",
        "    # Vy2 = (cy3 - cy2) / dt\n",
        "\n",
        "    # Ax = (Vx2 - Vx1) / dt\n",
        "    # Ay = (Vy2 - Vy1) / dt\n",
        "\n",
        "    Vx1 = (cx2 - cx1)\n",
        "    Vy1 = (cy2 - cy1)\n",
        "    Vx2 = (cx3 - cx2)\n",
        "    Vy2 = (cy3 - cy2)\n",
        "\n",
        "    Ax = (Vx2 - Vx1)\n",
        "    Ay = (Vy2 - Vy1)\n",
        "\n",
        "    return Vx1, Vy1, Ax, Ay\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      fr:\n",
        "      r:\n",
        "      v:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      data:\n",
        "      cutoff:\n",
        "      fs:\n",
        "      order:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    nyquist = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "image_folder = 'newmethod'\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "dt = 1 / 30.0\n",
        "\n",
        "results = []\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "    Vx, Vy, Ax, Ay = compute_velocity_and_acceleration((cx1, cy1), (cx2, cy2), (cx3, cy3), dt)\n",
        "    results.append([i+1, cx1, cy1, Vx, Vy, Ax, Ay])\n",
        "\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay'])\n",
        "window_length = min(7, len(df))\n",
        "\n",
        "# Savitzky-Golay フィルタ\n",
        "df['Vx_smooth_sg'] = savgol_filter(df['Vx'], window_length=window_length, polyorder=2)\n",
        "df['Vy_smooth_sg'] = savgol_filter(df['Vy'], window_length=window_length, polyorder=2)\n",
        "\n",
        "# バターワースフィルタ\n",
        "cutoff = 2.0  # カットオフ周波数\n",
        "fs = 30.0  # サンプリング周波数\n",
        "df['Vx_smooth_butter'] = butter_lowpass_filter(df['Vx'], cutoff, fs)\n",
        "df['Vy_smooth_butter'] = butter_lowpass_filter(df['Vy'], cutoff, fs)\n",
        "\n",
        "# ガウシアンフィルタ\n",
        "df['Vx_smooth_gaussian'] = gaussian_filter1d(df['Vx'], sigma=2)\n",
        "df['Vy_smooth_gaussian'] = gaussian_filter1d(df['Vy'], sigma=2)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 平滑化後の速度から加速度を再計算\n",
        "df['Ax_smooth'] = df['Vx_smooth_butter'].diff()\n",
        "df['Ay_smooth'] = df['Vy_smooth_butter'].diff()\n",
        "df['Ax_smooth'] = df['Ax_smooth'].fillna(0)\n",
        "df['Ay_smooth'] = df['Ay_smooth'].fillna(0)\n",
        "# df['Ax_smooth_gaussian'] = gaussian_filter1d(df['Ax_smooth'], sigma=40)\n",
        "# df['Ay_smooth_gaussian'] = gaussian_filter1d(df['Ay_smooth'], sigma=40)\n",
        "# Gaussian Filter with padding\n",
        "sigma = 40  # Standard deviation for Gaussian filter\n",
        "Ax_smooth_padded = np.pad(df['Ax_smooth'], (sigma, sigma), mode='reflect')\n",
        "Ay_smooth_padded = np.pad(df['Ay_smooth'], (sigma, sigma), mode='reflect')\n",
        "\n",
        "Ax_smooth_gaussian = gaussian_filter1d(Ax_smooth_padded, sigma=sigma)\n",
        "Ay_smooth_gaussian = gaussian_filter1d(Ay_smooth_padded, sigma=sigma)\n",
        "df['Ax_smooth_gaussian'] = Ax_smooth_gaussian[sigma:-sigma]\n",
        "df['Ay_smooth_gaussian'] = Ay_smooth_gaussian[sigma:-sigma]\n",
        "\n",
        "# Butterworth Filter\n",
        "# df['Ax_smooth'] = df['Ax_smooth'].fillna(0)\n",
        "# df['Ay_smooth'] = df['Ay_smooth'].fillna(0)\n",
        "# N = 2  # Order of the filter\n",
        "# Wn = 0.03  # Cutoff frequency\n",
        "# b, a = butter(N, Wn)\n",
        "# df['Ax_smooth_butter'] = filtfilt(b, a, df['Ax_smooth'])\n",
        "# df['Ay_smooth_butter'] = filtfilt(b, a, df['Ay_smooth'])\n",
        "# df['Ax_smooth_butter'] = butter_lowpass_filter(df['Ax_smooth'], cutoff, fs)\n",
        "# df['Ay_smooth_butter'] = butter_lowpass_filter(df['Ay_smooth'], cutoff, fs)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 各フレームに加速度ベクトルを描画\n",
        "for i in range(len(image_files) - 2):\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    cx2, cy2 = df.loc[i, ['X', 'Y']]\n",
        "    print(df.loc[i, ['Ax_smooth_gaussian', 'Ay_smooth_gaussian']])\n",
        "    Ax, Ay = df.loc[i, ['Ax_smooth_gaussian', 'Ay_smooth_gaussian']]\n",
        "\n",
        "    start_point = (int(cx2), int(cy2))\n",
        "    end_point = (int(cx2 + Ax * 10 ** 4), int(cy2 + Ay * 10 ** 4))\n",
        "    cv2.arrowedLine(image2, start_point, end_point, (0, 0, 255), 2)\n",
        "    cv2.imwrite(f'./demo/output_frame_{i+1}.png', image2)\n",
        "\n",
        "df.to_csv('centroid_based_acceleration_smoothV3.csv', index=False)\n",
        "print(\"結果をcentroid_based_acceleration_smoothV3.csvに保存し、フレームを保存しました。\")\n"
      ],
      "metadata": {
        "id": "yV3wUsvCvTRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(df)\n",
        "# df.loc[10, ['Ax_smooth', 'Ay_smooth']]\n",
        "df['Ay_smooth_butter'].plot()\n",
        "df['Ax_smooth_butter'].plot()"
      ],
      "metadata": {
        "id": "Ge4PMNhEcmF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Ay_smooth_butter'].plot()"
      ],
      "metadata": {
        "id": "0DHAmgoZjfQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# サンプルデータの作成\n",
        "# data = {\n",
        "#     'Frame': np.arange(0, 100),\n",
        "#     'A_smooth': np.linspace(1, 3, 100) + 0.05 * np.sin(0.2 * np.pi * frames) + 0.05 * np.cos(0.3 * np.pi * frames),\n",
        "#     'theoA': np.linspace(1, 3, 100)  # 理論値の線形補間\n",
        "# }\n",
        "read_csv = pd.read_csv('centroidBasedAccelerationSmoothV3.csv')\n",
        "data = {\n",
        "    'Frame': read_csv['Frame'],\n",
        "    'A_smooth': read_csv['A_smooth'],\n",
        "    'theoA': read_csv['theoA']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# データの抽出\n",
        "frames = df['Frame']\n",
        "A_smooth = df['A_smooth']\n",
        "theoA = df['theoA']\n",
        "\n",
        "# 平滑化手法の適用\n",
        "# 移動平均\n",
        "window_size = 7\n",
        "A_smooth_moving_avg = A_smooth.rolling(window=window_size).mean()\n",
        "\n",
        "# ガウシアンフィルタ\n",
        "sigma = 40  # ガウシアンフィルタの標準偏差\n",
        "A_smooth_gaussian = gaussian_filter1d(A_smooth, sigma=sigma)\n",
        "\n",
        "# サビツキー・ゴレイフィルタ\n",
        "window_length = 20\n",
        "polyorder = 5\n",
        "A_smooth_savgol = savgol_filter(A_smooth, window_length, polyorder)\n",
        "\n",
        "# オリジナル、理論値、および平滑化されたデータのプロット\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(frames, A_smooth, label='Original A_smooth', alpha=0.5)\n",
        "plt.plot(frames, theoA, label='Theoretical A (theoA)', linestyle='--')\n",
        "plt.plot(frames, A_smooth_moving_avg, label='Moving Average Smooth', linewidth=2)\n",
        "plt.plot(frames, A_smooth_gaussian, label='Gaussian Smooth', linewidth=2)\n",
        "plt.plot(frames, A_smooth_savgol, label='Savitzky-Golay Smooth', linewidth=2)\n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('Acceleration')\n",
        "plt.title('Comparison of Smoothing Techniques to Theoretical Acceleration')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IbKzmaR0F1nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ace_tools"
      ],
      "metadata": {
        "id": "Cbznf8tbOZSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import savgol_filter, butter, filtfilt\n",
        "\n",
        "# Sample data generation with a specific pattern for A_smooth around theoA\n",
        "# np.random.seed(42)\n",
        "# frames = np.arange(0, 1000)\n",
        "# theoA = np.linspace(1, 3, 1000)\n",
        "# A_smooth = theoA + 0.3 * np.sin(0.2 * np.pi * frames) + 0.1 * np.random.randn(1000)\n",
        "\n",
        "# Create DataFrame\n",
        "# df = pd.DataFrame({\n",
        "#     'Frame': frames,\n",
        "#     'A_smooth': A_smooth,\n",
        "#     'theoA': theoA\n",
        "# })\n",
        "\n",
        "read_csv = pd.read_csv('centroidBasedAccelerationSmoothV3.csv')\n",
        "df = {\n",
        "    'Frame': read_csv['Frame'],\n",
        "    'A_smooth': read_csv['A_smooth'],\n",
        "    'theoA': read_csv['theoA']\n",
        "}\n",
        "\n",
        "# Moving Average\n",
        "window_size = 25\n",
        "df['A_smooth_moving_avg'] = df['A_smooth'].rolling(window=window_size).mean()\n",
        "\n",
        "# # Gaussian Filter\n",
        "# sigma = 15  # Standard deviation for Gaussian filter\n",
        "# df['A_smooth_gaussian'] = gaussian_filter1d(df['A_smooth'], sigma=sigma)\n",
        "\n",
        "# Gaussian Filter with padding\n",
        "sigma = 10  # Standard deviation for Gaussian filter\n",
        "A_smooth_padded = np.pad(df['A_smooth'], pad_width=sigma, mode='reflect')\n",
        "A_smooth_gaussian = gaussian_filter1d(A_smooth_padded, sigma=sigma)\n",
        "df['A_smooth_gaussian'] = A_smooth_gaussian[sigma:-sigma]\n",
        "\n",
        "# Savitzky-Golay Filter\n",
        "window_length = 60\n",
        "polyorder = 4\n",
        "df['A_smooth_savgol'] = savgol_filter(df['A_smooth'], window_length, polyorder)\n",
        "\n",
        "# Butterworth Filter\n",
        "N = 2  # Order of the filter\n",
        "Wn = 0.03  # Cutoff frequency\n",
        "b, a = butter(N, Wn)\n",
        "df['A_smooth_butter'] = filtfilt(b, a, df['A_smooth'])\n",
        "\n",
        "# Kalman Filter Implementation\n",
        "def kalman_filter(data, Q, R):\n",
        "    n = len(data)\n",
        "    x = np.zeros(n)\n",
        "    P = np.zeros(n)\n",
        "    x[0] = data[0]\n",
        "    P[0] = 1.0\n",
        "    for k in range(1, n):\n",
        "        # Prediction step\n",
        "        x_pred = x[k-1]\n",
        "        P_pred = P[k-1] + Q\n",
        "        # Update step\n",
        "        K = P_pred / (P_pred + R)\n",
        "        x[k] = x_pred + K * (data[k] - x_pred)\n",
        "        P[k] = (1 - K) * P_pred\n",
        "    return x\n",
        "\n",
        "# Set process variance (Q) and measurement variance (R)\n",
        "Q = 0.001  # Process variance (Adjusted)\n",
        "R = 5.0  # Measurement variance (Adjusted)\n",
        "\n",
        "# Apply Kalman Filter\n",
        "df['A_smooth_kalman'] = kalman_filter(df['A_smooth'], Q, R)\n",
        "\n",
        "# Plot the original, theoretical, and smoothed data\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(df['Frame'], df['A_smooth'], label='Original A_smooth', alpha=0.5)\n",
        "plt.plot(df['Frame'], df['theoA'], label='Theoretical A (theoA)', linestyle='--')\n",
        "plt.plot(df['Frame'], df['A_smooth_moving_avg'], label='Moving Average Smooth', linewidth=2)\n",
        "plt.plot(df['Frame'], df['A_smooth_gaussian'], label='Gaussian Smooth', linewidth=2)\n",
        "plt.plot(df['Frame'], df['A_smooth_savgol'], label='Savitzky-Golay Smooth', linewidth=2)\n",
        "plt.plot(df['Frame'], df['A_smooth_butter'], label='Butterworth Smooth', linewidth=2)\n",
        "plt.plot(df['Frame'], df['A_smooth_kalman'], label='Kalman Smooth', linewidth=2)\n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('Acceleration')\n",
        "plt.title('Comparison of Smoothing Techniques to Theoretical Acceleration')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Optimized Smoothing Techniques Data\", dataframe=df)\n",
        "\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "VTahorFdOOK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import savgol_filter, butter, filtfilt\n",
        "\n",
        "# Sample data generation with a specific pattern for A_smooth around theoA\n",
        "# np.random.seed(42)\n",
        "# frames = np.arange(0, 1000)\n",
        "# theoA = np.linspace(1, 3, 1000)\n",
        "# A_smooth = theoA + 0.3 * np.sin(0.2 * np.pi * frames) + 0.1 * np.random.randn(1000)\n",
        "\n",
        "# Create DataFrame\n",
        "# df = pd.DataFrame({\n",
        "#     'Frame': frames,\n",
        "#     'A_smooth': A_smooth,\n",
        "#     'theoA': theoA\n",
        "# })\n",
        "\n",
        "read_csv = pd.read_csv('centroidBasedAccelerationSmoothV3.csv')\n",
        "df = {\n",
        "    'Frame': read_csv['Frame'],\n",
        "    'TheoAy': read_csv['TheoAy'],\n",
        "    'TheoAx': read_csv['TheoAx'],\n",
        "    'Ay_smooth': read_csv['Ay_smooth'],\n",
        "    'Ax_smooth': read_csv['Ax_smooth']\n",
        "}\n",
        "\n",
        "# Moving Average\n",
        "window_size = 25\n",
        "df['Ax_smooth_moving_avg'] = df['Ax_smooth'].rolling(window=window_size).mean()\n",
        "df['Ay_smooth_moving_avg'] = df['Ay_smooth'].rolling(window=window_size).mean()\n",
        "\n",
        "\n",
        "# Gaussian Filter with padding\n",
        "sigma = 40  # Standard deviation for Gaussian filter\n",
        "Ax_smooth_padded = np.pad(df['Ax_smooth'], (sigma, sigma), mode='reflect')\n",
        "Ay_smooth_padded = np.pad(df['Ay_smooth'], (sigma, sigma), mode='reflect')\n",
        "\n",
        "Ax_smooth_gaussian = gaussian_filter1d(Ax_smooth_padded, sigma=sigma)\n",
        "Ay_smooth_gaussian = gaussian_filter1d(Ay_smooth_padded, sigma=sigma)\n",
        "df['Ax_smooth_gaussian'] = Ax_smooth_gaussian[sigma:-sigma]\n",
        "df['Ay_smooth_gaussian'] = Ay_smooth_gaussian[sigma:-sigma]\n",
        "\n",
        "\n",
        "# Savitzky-Golay Filter\n",
        "window_length = 60\n",
        "polyorder = 4\n",
        "df['Ax_smooth_savgol'] = savgol_filter(df['Ax_smooth'], window_length, polyorder)\n",
        "df['Ay_smooth_savgol'] = savgol_filter(df['Ay_smooth'], window_length, polyorder)\n",
        "\n",
        "\n",
        "# Butterworth Filter\n",
        "N = 2  # Order of the filter\n",
        "Wn = 0.03  # Cutoff frequency\n",
        "b, a = butter(N, Wn)\n",
        "df['Ax_smooth_butter'] = filtfilt(b, a, df['Ax_smooth'])\n",
        "df['Ay_smooth_butter'] = filtfilt(b, a, df['Ay_smooth'])\n",
        "\n",
        "\n",
        "# Kalman Filter Implementation\n",
        "def kalman_filter(data, Q, R):\n",
        "    n = len(data)\n",
        "    x = np.zeros(n)\n",
        "    P = np.zeros(n)\n",
        "    x[0] = data[0]\n",
        "    P[0] = 1.0\n",
        "    for k in range(1, n):\n",
        "        # Prediction step\n",
        "        x_pred = x[k-1]\n",
        "        P_pred = P[k-1] + Q\n",
        "        # Update step\n",
        "        K = P_pred / (P_pred + R)\n",
        "        x[k] = x_pred + K * (data[k] - x_pred)\n",
        "        P[k] = (1 - K) * P_pred\n",
        "    return x\n",
        "\n",
        "# Set process variance (Q) and measurement variance (R)\n",
        "Q = 0.001  # Process variance (Adjusted)\n",
        "R = 5.0  # Measurement variance (Adjusted)\n",
        "\n",
        "# Apply Kalman Filter\n",
        "df['Ax_smooth_kalman'] = kalman_filter(df['Ax_smooth'], Q, R)\n",
        "df['Ay_smooth_kalman'] = kalman_filter(df['Ay_smooth'], Q, R)\n",
        "\n",
        "\n",
        "# Plot the original, theoretical, and smoothed data\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(df['Frame'], df['Ax_smooth'], label='Original Ax_smooth', alpha=0.5)\n",
        "plt.plot(df['Frame'], df['TheoAx'], label='Theoretical Ax (theoAx)', linestyle='--')\n",
        "# plt.plot(df['Frame'], df['Ax_smooth_moving_avg'], label='Moving Average Smoothx', linewidth=2)\n",
        "plt.plot(df['Frame'], df['Ax_smooth_gaussian'], label='Gaussian Smoothx', linewidth=2)\n",
        "# plt.plot(df['Frame'], df['Ax_smooth_savgol'], label='Savitzky-Golay Smoothx', linewidth=2)\n",
        "plt.plot(df['Frame'], df['Ax_smooth_butter'], label='Butterworth Smoothx', linewidth=2)\n",
        "# plt.plot(df['Frame'], df['Ax_smooth_kalman'], label='Kalman Smoothx', linewidth=2)\n",
        "plt.plot(df['Frame'], df['Ay_smooth'], label='Original Ay_smooth', alpha=0.5)\n",
        "plt.plot(df['Frame'], df['TheoAy'], label='Theoretical Ay (theoAy)', linestyle='--')\n",
        "# plt.plot(df['Frame'], df['Ay_smooth_moving_avg'], label='Moving Average Smoothy', linewidth=2)\n",
        "plt.plot(df['Frame'], df['Ay_smooth_gaussian'], label='Gaussian Smoothy', linewidth=2)\n",
        "# plt.plot(df['Frame'], df['Ay_smooth_savgol'], label='Savitzky-Golay Smoothy', linewidth=2)\n",
        "plt.plot(df['Frame'], df['Ay_smooth_butter'], label='Butterworth Smoothy', linewidth=2)\n",
        "# plt.plot(df['Frame'], df['Ay_smooth_kalman'], label='Kalman Smoothy', linewidth=2)\n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('Acceleration')\n",
        "plt.title('Comparison of Smoothing Techniques to Theoretical Acceleration')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Optimized Smoothing Techniques Data\", dataframe=df)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "fIIL1y08UxSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(df)\n",
        "df['Ax_smooth_gaussian'].head()"
      ],
      "metadata": {
        "id": "JMpHDX7ndeWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Ay_smooth_gaussian'].head()"
      ],
      "metadata": {
        "id": "3zF8JbnDdyYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.signal import savgol_filter, butter, filtfilt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from filterpy.kalman import KalmanFilter\n",
        "\n",
        "def initialize_kalman_filter():\n",
        "    kf = KalmanFilter(dim_x=2, dim_z=1)\n",
        "    kf.F = np.array([[1, 1], [0, 1]])  # 状態遷移行列\n",
        "    kf.H = np.array([[1, 0]])          # 観測行列\n",
        "    kf.P *= 1000.                      # 誤差共分散行列の初期設定\n",
        "    kf.R = np.array([[5]])             # 観測ノイズの共分散\n",
        "    kf.Q = np.array([[1, 0], [0, 1]])  # プロセスノイズの共分散\n",
        "    kf.x = np.array([[0], [0]])        # 初期状態\n",
        "    return kf\n",
        "\n",
        "def kalman_filter_acceleration(data):\n",
        "    kf = initialize_kalman_filter()\n",
        "    filtered_data = []\n",
        "    for measurement in data:\n",
        "        kf.predict()\n",
        "        kf.update([measurement])\n",
        "        filtered_data.append(kf.x[0][0])\n",
        "    return np.array(filtered_data)\n",
        "\n",
        "def segment_and_compute_centroid(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    moments = cv2.moments(binary)\n",
        "    if moments['m00'] != 0:\n",
        "        cx = moments['m10'] / moments['m00']\n",
        "        cy = moments['m01'] / moments['m00']\n",
        "    else:\n",
        "        cx, cy = 0.0, 0.0\n",
        "    return cx, cy\n",
        "\n",
        "def compute_velocity_and_acceleration(centroid1, centroid2, centroid3, dt):\n",
        "    cx1, cy1 = centroid1\n",
        "    cx2, cy2 = centroid2\n",
        "    cx3, cy3 = centroid3\n",
        "\n",
        "    Vx1 = (cx2 - cx1) / dt\n",
        "    Vy1 = (cy2 - cy1) / dt\n",
        "    Vx2 = (cx3 - cx2) / dt\n",
        "    Vy2 = (cy3 - cy2) / dt\n",
        "\n",
        "    Ax = (Vx2 - Vx1) / dt\n",
        "    Ay = (Vy2 - Vy1) / dt\n",
        "\n",
        "    return Vx1, Vy1, Ax, Ay\n",
        "\n",
        "def theoretical_values(fr, r, v):\n",
        "    w = v / r\n",
        "    x = r * np.cos(w * fr)\n",
        "    y = r * np.sin(w * fr)\n",
        "    Vx = -v * np.sin(w * fr)\n",
        "    Vy = v * np.cos(w * fr)\n",
        "    Ax = -v * w * np.cos(w * fr)\n",
        "    Ay = -v * w * np.sin(w * fr)\n",
        "    return x, y, Vx, Vy, Ax, Ay\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "image_folder = 'newmethod'\n",
        "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "dt = 1 / 30.0\n",
        "\n",
        "results = []\n",
        "for i in range(len(image_files) - 2):\n",
        "    image1 = cv2.imread(image_files[i])\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    image3 = cv2.imread(image_files[i + 2])\n",
        "    cx1, cy1 = segment_and_compute_centroid(image1)\n",
        "    cx2, cy2 = segment_and_compute_centroid(image2)\n",
        "    cx3, cy3 = segment_and_compute_centroid(image3)\n",
        "    Vx, Vy, Ax, Ay = compute_velocity_and_acceleration((cx1, cy1), (cx2, cy2), (cx3, cy3), dt)\n",
        "    results.append([i+1, cx1, cy1, Vx, Vy, Ax, Ay])\n",
        "\n",
        "df = pd.DataFrame(results, columns=['Frame', 'X', 'Y', 'Vx', 'Vy', 'Ax', 'Ay'])\n",
        "\n",
        "# Savitzky-Golay フィルタ\n",
        "window_length = min(7, len(df))\n",
        "df['Vx_smooth_sg'] = savgol_filter(df['Vx'], window_length=window_length, polyorder=2)\n",
        "df['Vy_smooth_sg'] = savgol_filter(df['Vy'], window_length=window_length, polyorder=2)\n",
        "\n",
        "# バターワースフィルタ\n",
        "cutoff = 2.0  # カットオフ周波数\n",
        "fs = 30.0  # サンプリング周波数\n",
        "df['Vx_smooth_butter'] = butter_lowpass_filter(df['Vx'], cutoff, fs)\n",
        "df['Vy_smooth_butter'] = butter_lowpass_filter(df['Vy'], cutoff, fs)\n",
        "\n",
        "# ガウシアンフィルタ\n",
        "df['Vx_smooth_gaussian'] = gaussian_filter1d(df['Vx'], sigma=2)\n",
        "df['Vy_smooth_gaussian'] = gaussian_filter1d(df['Vy'], sigma=2)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 平滑化後の速度から加速度を再計算\n",
        "df['Ax_smooth'] = df['Vx_smooth_butter'].diff() / dt\n",
        "df['Ay_smooth'] = df['Vy_smooth_butter'].diff() / dt\n",
        "\n",
        "df['Ax_smooth'] = df['Ax_smooth'].fillna(0)\n",
        "df['Ay_smooth'] = df['Ay_smooth'].fillna(0)\n",
        "sigma = 40  # Standard deviation for Gaussian filter\n",
        "Ax_smooth_padded = np.pad(df['Ax_smooth'], (sigma, sigma), mode='reflect')\n",
        "Ay_smooth_padded = np.pad(df['Ay_smooth'], (sigma, sigma), mode='reflect')\n",
        "\n",
        "Ax_smooth_gaussian = gaussian_filter1d(Ax_smooth_padded, sigma=sigma)\n",
        "Ay_smooth_gaussian = gaussian_filter1d(Ay_smooth_padded, sigma=sigma)\n",
        "df['Ax_smooth_gaussian'] = Ax_smooth_gaussian[sigma:-sigma]\n",
        "df['Ay_smooth_gaussian'] = Ay_smooth_gaussian[sigma:-sigma]\n",
        "# df['Ax_smooth_butter'] = butter_lowpass_filter(df['Ax_smooth'], cutoff, fs)\n",
        "# df['Ay_smooth_butter'] = butter_lowpass_filter(df['Ay_smooth'], cutoff, fs)\n",
        "\n",
        "# 動画ライターの初期化\n",
        "output_video = 'output_video.avi'\n",
        "frame_width = int(image2.shape[1])\n",
        "frame_height = int(image2.shape[0])\n",
        "out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'XVID'), 30, (frame_width, frame_height))\n",
        "\n",
        "# 各フレームに加速度ベクトルを描画\n",
        "for i in range(len(image_files) - 2):\n",
        "    image2 = cv2.imread(image_files[i + 1])\n",
        "    cx2, cy2 = df.loc[i, ['X', 'Y']]\n",
        "    Ax, Ay = df.loc[i, ['Ax_smooth_gaussianr', 'Ay_smooth_gaussian']]\n",
        "\n",
        "    start_point = (int(cx2), int(cy2))\n",
        "    end_point = (int(cx2 + Ax * 10), int(cy2 + Ay * 10))\n",
        "    cv2.arrowedLine(image2, start_point, end_point, (0, 0, 255), 2)\n",
        "\n",
        "    # フレームを動画に追加\n",
        "    out.write(image2)\n",
        "\n",
        "# 動画ライターを解放\n",
        "out.release()\n",
        "\n",
        "df.to_csv('centroid_based_acceleration_smoothV3.csv', index=False)\n",
        "print(\"結果をcentroid_based_acceleration_smoothV3.csvに保存し、動画を生成しました。\")\n"
      ],
      "metadata": {
        "id": "4wRkoC7XrBz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 動画書き起こし"
      ],
      "metadata": {
        "id": "lERRxwCfrqfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def create_video_from_frames(image_folder, output_video, fps=30):\n",
        "    # 画像ファイルを取得\n",
        "    image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "    # 最初のフレームを読み込み、フレームのサイズを取得\n",
        "    first_frame = cv2.imread(image_files[0])\n",
        "    frame_height, frame_width, _ = first_frame.shape\n",
        "\n",
        "    # 動画ライターの初期化\n",
        "    out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
        "\n",
        "    # 各画像を動画に追加\n",
        "    for image_file in image_files:\n",
        "        frame = cv2.imread(image_file)\n",
        "        out.write(frame)\n",
        "\n",
        "    # 動画ライターを解放\n",
        "    out.release()\n",
        "    print(f\"動画ファイル {output_video} を作成しました。\")\n",
        "\n",
        "# 使用例\n",
        "image_folder = 'demo'  # 画像が保存されているフォルダのパス\n",
        "output_video = './output_video.avi'      # 作成する動画ファイルの名前\n",
        "fps = 30                              # フレームレート\n",
        "\n",
        "create_video_from_frames(image_folder, output_video, fps)\n"
      ],
      "metadata": {
        "id": "f9o2SShPrqEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import decimal\n",
        "import math\n",
        "\n",
        "# decimal のコンテキスト設定\n",
        "decimal.getcontext().prec = 50  # 精度を50桁に設定\n",
        "\n",
        "# 円運動のパラメータ\n",
        "r = decimal.Decimal('1.0')  # 半径\n",
        "omega = decimal.Decimal('1.0')  # 角速度\n",
        "\n",
        "# 時間の変化\n",
        "dt = decimal.Decimal('0.01')  # 時間の微小変化\n",
        "\n",
        "# 速度の計算\n",
        "# 速度ベクトル v(t) = (-r * omega * sin(omega * t), r * omega * cos(omega * t))\n",
        "def velocity(t):\n",
        "    vx = -r * omega * decimal.Decimal(math.sin(float(omega * t)))\n",
        "    vy = r * omega * decimal.Decimal(math.cos(float(omega * t)))\n",
        "    return (vx, vy)\n",
        "\n",
        "# 速度ベクトルの差分を求める\n",
        "t1 = decimal.Decimal('0.0')  # 時刻 t1\n",
        "t2 = t1 + dt  # 時刻 t2\n",
        "\n",
        "v1 = velocity(t1)  # 時刻 t1 の速度\n",
        "v2 = velocity(t2)  # 時刻 t2 の速度\n",
        "\n",
        "# 速度ベクトルの差分\n",
        "dvx = v2[0] - v1[0]\n",
        "dvy = v2[1] - v1[1]\n",
        "\n",
        "# 加速度ベクトル (a = dv/dt)\n",
        "ax = dvx / dt\n",
        "ay = dvy / dt\n",
        "\n",
        "print(\"速度ベクトルの差分:\")\n",
        "print(f\"dvx: {dvx}\")\n",
        "print(f\"dvy: {dvy}\")\n",
        "\n",
        "print(\"加速度ベクトル:\")\n",
        "print(f\"ax: {ax}\")\n",
        "print(f\"ay: {ay}\")\n"
      ],
      "metadata": {
        "id": "cqG-YJfltjLC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}